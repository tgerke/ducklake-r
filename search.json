[{"path":"https://tgerke.github.io/ducklake-r/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 ducklake authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Clinical Trial Data Lake with ducklake","text":"Electronic Data Capture (EDC) systems provide built-logging audit trails collected clinical trial data, significant data management challenges emerge data exported EDC statistical programming analysis. SDTM datasets created analysis begins, traditional file-based approaches often result : Disconnected Flat Files: CDISC datasets inherently relational (linked USUBJID, domain keys) typically stored separate XPT/CSV files isolated SAS datasets, often requiring manual loading joining cross-domain analyses Loss Audit Trail: EDC protections disappear; tracking changes derived datasets becomes manual Version Control Challenges: Multiple versions analysis datasets scattered across folders drives Data Lineage Issues: Unclear provenance derived variables ADaM datasets Reproducibility Concerns: Inability recreate analyses specific time points Collaboration Friction: Multiple statistical programmers working different versions data Regulatory Gaps: Difficulty demonstrating 21 CFR Part 11 compliance derived datasets ducklake package addresses post-EDC challenges implementing versioned data lake architecture specifically designed statistical programming workflows R. Rather managing disconnected flat files, DuckLake provides modern relational database structure preserves inherent relationships CDISC datasets adding enterprise-grade version control. storing SDTM (Study Data Tabulation Model) ADaM (Analysis Data Model) datasets along regulatory submission artifacts (define.xml, ARD, ARM, specifications) DuckLake, statistical programmers gain: Relational Data Model: CDISC datasets inherently relational explicit keys (USUBJID, domain relationships) traditionally stored disconnected flat files (XPT, CSV). DuckLake preserves relational structure, enabling efficient joins queries across domains without loading multiple files Modern Data Architecture: Move file-based database-backed workflows maintaining R’s familiar data frame interface Automatic Versioning: Every data modification tracked timestamps metadata Time Travel: Query data existed point time Audit Trail: Complete history data changes regulatory compliance Reproducibility: Recreate analyses exactly run previously Collaboration: Multiple analysts can work safely shared data Performance: Fast queries large datasets using DuckDB’s columnar storage query optimization Transactions: Atomic updates ensure data consistency across related datasets Unified Storage: Keep datasets alongside regulatory artifacts (define.xml, ARD, ARM) one versioned repository vignette demonstrates set clinical trial data lake, starting SDTM domains building analysis-ready ADaM datasets, including storage regulatory submission artifacts.","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"setting-up-the-data-lake","dir":"Articles","previous_headings":"","what":"Setting Up the Data Lake","title":"Clinical Trial Data Lake with ducklake","text":"First, ’ll create new DuckLake store clinical trial data. establishes foundational infrastructure versioned data repository. ’ll use temporary directory vignette, practice specify permanent location using lake_path argument (e.g., shared network drive project directory).","code":"# Install the ducklake extension to duckdb (required once per system) install_ducklake()  # Define where to create a new data lake or access an existing one # For this vignette, we use tempdir(); in practice, use a permanent location # lake_path <- \"/path/to/your/project/data_lake\" trial_lake_path <- tempdir()  # attach_ducklake creates or attaches (if it already exists) a data lake attach_ducklake(   ducklake_name = \"clinical_trial_lake\",   lake_path = trial_lake_path )  # Verify the lake was created list.files(trial_lake_path, pattern = \"clinical_trial_lake\") #> [1] \"clinical_trial_lake.ducklake\"     \"clinical_trial_lake.ducklake.wal\""},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"data-lake-architecture-medallion-layers","dir":"Articles","previous_headings":"","what":"Data Lake Architecture: Medallion Layers","title":"Clinical Trial Data Lake with ducklake","text":"loading data, ’s important understand layered architecture ’ll use. follows medallion architecture pattern common modern data lakes: Bronze Layer (Raw): Data exactly received source systems, transformations. preserves original data audit trails reprocessing. Silver Layer (Cleaned): Standardized cleaned data transformations like convert_blanks_to_na(), type conversions, validation. trusted source deriving analysis datasets. Gold Layer (Analytics): Business-logic datasets optimized specific analyses, ADaM datasets. analysis happens. approach provides: Complete Audit Trail: Original data preserved alongside transformations Reprocessability: cleaning logic changes, reprocess bronze without re-extracting Data Lineage: Clear progression raw → cleaned → analysis-ready Validation: Compare layers verify transformations Regulatory Compliance: Demonstrate source data lost improperly altered","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"loading-sdtm-domains","dir":"Articles","previous_headings":"","what":"Loading SDTM Domains","title":"Clinical Trial Data Lake with ducklake","text":"SDTM datasets form foundation clinical trial data. ’ll load several key domains pharmaverse SDTM collection, contains realistic test data CDISC pilot study. domain, ’ll: 1. Load raw data bronze layer (received) 2. Apply cleaning transformations create silver layer (analysis-ready)","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"demographics-dm","dir":"Articles","previous_headings":"Loading SDTM Domains","what":"Demographics (DM)","title":"Clinical Trial Data Lake with ducklake","text":"Demographics domain contains baseline characteristics subject.","code":"# Bronze layer: Load raw SDTM Demographics exactly as received with_transaction(   create_table(pharmaversesdtm::dm, \"dm_raw\"),   author = \"T Gerke\",   commit_message = \"Add raw demographics\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Silver layer: Apply cleaning transformations with_transaction(   get_ducklake_table(\"dm_raw\") |>      admiral::convert_blanks_to_na() |>      create_table(\"dm\"),   author = \"T Gerke\",   commit_message = \"Clean demographics data\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Verify the cleaned table get_ducklake_table(\"dm\") |>    select(USUBJID, AGE, SEX, RACE, ARM) |>    head() #> # Source:   SQL [?? x 5] #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #>   USUBJID       AGE SEX   RACE  ARM                  #>   <chr>       <dbl> <chr> <chr> <chr>                #> 1 01-701-1015    63 F     WHITE Placebo              #> 2 01-701-1023    64 M     WHITE Placebo              #> 3 01-701-1028    71 M     WHITE Xanomeline High Dose #> 4 01-701-1033    74 M     WHITE Xanomeline Low Dose  #> 5 01-701-1034    77 F     WHITE Xanomeline High Dose #> 6 01-701-1047    85 F     WHITE Placebo"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"supplemental-demographics-suppdm","dir":"Articles","previous_headings":"Loading SDTM Domains","what":"Supplemental Demographics (SUPPDM)","title":"Clinical Trial Data Lake with ducklake","text":"Supplemental domains contain additional variables parent domain.","code":"# Bronze layer: Raw data with_transaction(   create_table(pharmaversesdtm::suppdm, \"suppdm_raw\"),   author = \"T Gerke\",   commit_message = \"Add raw supplemental demographics\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Silver layer: Cleaned data with_transaction(   get_ducklake_table(\"suppdm_raw\") |>      admiral::convert_blanks_to_na() |>      create_table(\"suppdm\"),   author = \"T Gerke\",   commit_message = \"Clean supplemental demographics\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"disposition-ds","dir":"Articles","previous_headings":"Loading SDTM Domains","what":"Disposition (DS)","title":"Clinical Trial Data Lake with ducklake","text":"Disposition domain tracks subject progress study.","code":"# Bronze layer with_transaction(   create_table(pharmaversesdtm::ds, \"ds_raw\"),   author = \"T Gerke\",   commit_message = \"Add raw disposition\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Silver layer with_transaction(   ds <- get_ducklake_table(\"ds_raw\") |>      admiral::convert_blanks_to_na() |>      create_table(\"ds\"),   author = \"T Gerke\",   commit_message = \"Clean disposition data\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"exposure-ex","dir":"Articles","previous_headings":"Loading SDTM Domains","what":"Exposure (EX)","title":"Clinical Trial Data Lake with ducklake","text":"Exposure domain contains treatment administration records.","code":"# Bronze layer with_transaction(   create_table(pharmaversesdtm::ex, \"ex_raw\"),   author = \"T Gerke\",   commit_message = \"Add raw exposure\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Silver layer with_transaction(   ex <- get_ducklake_table(\"ex_raw\") |>      admiral::convert_blanks_to_na() |>      create_table(\"ex\"),   author = \"T Gerke\",   commit_message = \"Clean exposure data\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"adverse-events-ae","dir":"Articles","previous_headings":"Loading SDTM Domains","what":"Adverse Events (AE)","title":"Clinical Trial Data Lake with ducklake","text":"Adverse Events domain records safety data.","code":"# Bronze layer with_transaction(   create_table(pharmaversesdtm::ae, \"ae_raw\"),   author = \"T Gerke\",   commit_message = \"Add raw adverse events\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Silver layer with_transaction(   ae <- get_ducklake_table(\"ae_raw\") |>      admiral::convert_blanks_to_na() |>      create_table(\"ae\"),   author = \"T Gerke\",   commit_message = \"Clean adverse events\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"vital-signs-vs","dir":"Articles","previous_headings":"Loading SDTM Domains","what":"Vital Signs (VS)","title":"Clinical Trial Data Lake with ducklake","text":"Vital Signs data used deriving baseline values.","code":"# Bronze layer with_transaction(   create_table(pharmaversesdtm::vs, \"vs_raw\"),   author = \"T Gerke\",   commit_message = \"Add raw vital signs\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Silver layer with_transaction(   vs <- get_ducklake_table(\"vs_raw\") |>      admiral::convert_blanks_to_na() |>      create_table(\"vs\"),   author = \"T Gerke\",   commit_message = \"Clean vital signs\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"pharmacokinetic-concentrations-pc","dir":"Articles","previous_headings":"Loading SDTM Domains","what":"Pharmacokinetic Concentrations (PC)","title":"Clinical Trial Data Lake with ducklake","text":"PK analysis, ’ll also load concentration data.","code":"# Bronze layer with_transaction(   create_table(pharmaversesdtm::pc, \"pc_raw\"),   author = \"T Gerke\",   commit_message = \"Add raw PK concentrations\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Silver layer with_transaction(   pc <- get_ducklake_table(\"pc_raw\") |>      admiral::convert_blanks_to_na() |>      create_table(\"pc\"),   author = \"T Gerke\",   commit_message = \"Clean PK concentrations\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"verifying-sdtm-version-control","dir":"Articles","previous_headings":"Loading SDTM Domains","what":"Verifying SDTM Version Control","title":"Clinical Trial Data Lake with ducklake","text":"Let’s verify SDTM data bronze silver layers indeed versioned. create_table() call within transaction automatically creates snapshot metadata. demonstrates : Every table creation versioned - bronze (dm_raw) silver (dm) layers version 1.0 Metadata captured - snapshot includes timestamp table information Time travel works - can retrieve specific version using get_ducklake_table_version() Audit trail exists - Complete history maintained regulatory compliance","code":"# View the first 5 of all snapshots in the data lake list_table_snapshots() |>   head(5) #>   snapshot_id       snapshot_time schema_version #> 1           0 2026-02-06 20:34:32              0 #> 2           1 2026-02-06 20:34:32              1 #> 3           2 2026-02-06 20:34:32              2 #> 4           3 2026-02-06 20:34:32              3 #> 5           4 2026-02-06 20:34:32              4 #>                                                    changes  author #> 1                                    schemas_created, main    <NA> #> 2     tables_created, tables_inserted_into, main.dm_raw, 1 T Gerke #> 3         tables_created, tables_inserted_into, main.dm, 2 T Gerke #> 4 tables_created, tables_inserted_into, main.suppdm_raw, 3 T Gerke #> 5     tables_created, tables_inserted_into, main.suppdm, 4 T Gerke #>                      commit_message commit_extra_info #> 1                              <NA>              <NA> #> 2              Add raw demographics              <NA> #> 3           Clean demographics data              <NA> #> 4 Add raw supplemental demographics              <NA> #> 5   Clean supplemental demographics              <NA>  # Filter snapshots for specific tables list_table_snapshots(\"dm_raw\") #>   snapshot_id       snapshot_time schema_version #> 2           1 2026-02-06 20:34:32              1 #>                                                changes  author #> 2 tables_created, tables_inserted_into, main.dm_raw, 1 T Gerke #>         commit_message commit_extra_info #> 2 Add raw demographics              <NA> list_table_snapshots(\"dm\") #>   snapshot_id       snapshot_time schema_version #> 3           2 2026-02-06 20:34:32              2 #>                                            changes  author #> 3 tables_created, tables_inserted_into, main.dm, 2 T Gerke #>            commit_message commit_extra_info #> 3 Clean demographics data              <NA>"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"building-the-analytics-layer-adam-datasets-gold-layer","dir":"Articles","previous_headings":"","what":"Building the Analytics Layer: ADaM Datasets (Gold Layer)","title":"Clinical Trial Data Lake with ducklake","text":"Now SDTM data loaded versioned silver layer, ’ll create analysis datasets following ADaM standards gold layer. datasets apply business logic derivations optimized specific analyses. dataset stored data lake full version control. gold layer reads silver layer (cleaned SDTM), ensuring analysis datasets built trusted, standardized source data.","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"adsl-subject-level-analysis-dataset","dir":"Articles","previous_headings":"Building the Analytics Layer: ADaM Datasets (Gold Layer)","what":"ADSL: Subject-Level Analysis Dataset","title":"Clinical Trial Data Lake with ducklake","text":"ADSL fundamental ADaM dataset containing one record per subject key analysis variables.","code":"# Read SDTM data from the lake and collect into memory # Admiral functions require tibbles/data.frames, not lazy database connections dm <- get_ducklake_table(\"dm\") |> collect() suppdm <- get_ducklake_table(\"suppdm\") |> collect() ds <- get_ducklake_table(\"ds\") |> collect() ex <- get_ducklake_table(\"ex\") |> collect() ae <- get_ducklake_table(\"ae\") |> collect() vs <- get_ducklake_table(\"vs\") |> collect()  # Combine DM and SUPPDM dm_suppdm <- dm |>    left_join(     suppdm |>        filter(QNAM %in% c(\"EDUCLVL\", \"DISCONFL\", \"DSRAEFL\")) |>        pivot_wider(         id_cols = c(STUDYID, USUBJID),         names_from = QNAM,         values_from = QVAL       ),     by = c(\"STUDYID\", \"USUBJID\")   )  # Derive treatment dates and durations ex_ext <- ex |>    derive_vars_dtm(     dtc = EXSTDTC,     new_vars_prefix = \"EXST\"   ) |>    derive_vars_dtm(     dtc = EXENDTC,     new_vars_prefix = \"EXEN\",     time_imputation = \"last\"   )  # Derive disposition variables first (needed for later derivations) ds_ext <- ds |>    derive_vars_dt(     dtc = DSSTDTC,     new_vars_prefix = \"DSST\"   )  # Build ADSL with all derivations in a single pipeline adsl <- dm_suppdm |>    # Treatment Start Datetime   derive_vars_merged(     dataset_add = ex_ext,     filter_add = (EXDOSE > 0 | (EXDOSE == 0 & str_detect(EXTRT, \"PLACEBO\"))) &                   !is.na(EXSTDTM),     new_vars = exprs(TRTSDTM = EXSTDTM),     order = exprs(EXSTDTM, EXSEQ),     mode = \"first\",     by_vars = exprs(STUDYID, USUBJID)   ) |>    # Treatment End Datetime   derive_vars_merged(     dataset_add = ex_ext,     filter_add = (EXDOSE > 0 | (EXDOSE == 0 & str_detect(EXTRT, \"PLACEBO\"))) &                   !is.na(EXENDTM),     new_vars = exprs(TRTEDTM = EXENDTM),     order = exprs(EXENDTM, EXSEQ),     mode = \"last\",     by_vars = exprs(STUDYID, USUBJID)   ) |>    # Convert to dates   derive_vars_dtm_to_dt(source_vars = exprs(TRTSDTM, TRTEDTM)) |>    # Treatment duration   derive_var_trtdurd() |>    # Safety population flag   derive_var_merged_exist_flag(     dataset_add = ex,     by_vars = exprs(STUDYID, USUBJID),     new_var = SAFFL,     condition = (EXDOSE > 0 | (EXDOSE == 0 & str_detect(EXTRT, \"PLACEBO\")))   ) |>    # Treatment variables   mutate(     TRT01P = ARM,     TRT01A = ACTARM   ) |>    # Age groups   mutate(     AGEGR1 = case_when(       AGE < 18 ~ \"<18\",       between(AGE, 18, 64) ~ \"18-64\",       AGE > 64 ~ \">64\",       TRUE ~ \"Missing\"     ),     AGEGR1N = case_when(       AGE < 18 ~ 1,       between(AGE, 18, 64) ~ 2,       AGE > 64 ~ 3,       TRUE ~ 4     )   ) |>    # Randomization date   derive_vars_merged(     dataset_add = ds_ext,     by_vars = exprs(STUDYID, USUBJID),     new_vars = exprs(RANDDT = DSSTDT),     filter_add = DSDECOD == \"RANDOMIZED\"   ) |>    # End of study date   derive_vars_merged(     dataset_add = ds_ext,     by_vars = exprs(STUDYID, USUBJID),     new_vars = exprs(EOSDT = DSSTDT),     filter_add = DSCAT == \"DISPOSITION EVENT\" & DSDECOD != \"SCREEN FAILURE\"   ) |>    # End of study status   mutate(     EOSSTT = case_when(       is.na(EOSDT) ~ \"ONGOING\",       TRUE ~ \"COMPLETED\"     )   )  # Store ADSL in the data lake with_transaction(   create_table(adsl, \"adsl\"),   author = \"T Gerke\",   commit_message = \"Create ADSL dataset\",   commit_extra_info = \"Derived from DM, SUPPDM, DS, EX; includes treatment dates, safety flags, age groups\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Preview ADSL get_ducklake_table(\"adsl\") |>    select(USUBJID, AGE, AGEGR1, TRT01P, TRTSDT, TRTEDT, SAFFL) |>   head(10) #> # Source:   SQL [?? x 7] #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #>    USUBJID       AGE AGEGR1 TRT01P               TRTSDT     TRTEDT     SAFFL #>    <chr>       <dbl> <chr>  <chr>                <date>     <date>     <chr> #>  1 01-701-1015    63 18-64  Placebo              2014-01-02 2014-07-02 Y     #>  2 01-701-1023    64 18-64  Placebo              2012-08-05 2012-09-01 Y     #>  3 01-701-1028    71 >64    Xanomeline High Dose 2013-07-19 2014-01-14 Y     #>  4 01-701-1033    74 >64    Xanomeline Low Dose  2014-03-18 2014-03-31 Y     #>  5 01-701-1034    77 >64    Xanomeline High Dose 2014-07-01 2014-12-30 Y     #>  6 01-701-1047    85 >64    Placebo              2013-02-12 2013-03-09 Y     #>  7 01-701-1057    59 18-64  Screen Failure       NA         NA         NA    #>  8 01-701-1097    68 >64    Xanomeline Low Dose  2014-01-01 2014-07-09 Y     #>  9 01-701-1111    81 >64    Xanomeline Low Dose  2012-09-07 2012-09-16 Y     #> 10 01-701-1115    84 >64    Xanomeline Low Dose  2012-11-30 2013-01-23 Y"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"adae-adverse-events-analysis-dataset","dir":"Articles","previous_headings":"Building the Analytics Layer: ADaM Datasets (Gold Layer)","what":"ADAE: Adverse Events Analysis Dataset","title":"Clinical Trial Data Lake with ducklake","text":"ADAE provides analysis-ready adverse event data treatment-emergent flags severity grades.","code":"# Read ADSL for merging adsl <- get_ducklake_table(\"adsl\") |> collect() ae <- get_ducklake_table(\"ae\") |> collect()  # Build ADAE adae <- ae |>   # Merge ADSL variables   derive_vars_merged(     dataset_add = adsl,     new_vars = exprs(TRTSDT, TRTEDT, TRT01A, TRT01P),     by_vars = exprs(STUDYID, USUBJID)   ) |>   # Derive analysis dates   derive_vars_dt(     dtc = AESTDTC,     new_vars_prefix = \"AST\"   ) |>   derive_vars_dt(     dtc = AEENDTC,     new_vars_prefix = \"AEN\",     date_imputation = \"last\"   ) |>   # Derive treatment-emergent flag   mutate(     TRTEMFL = if_else(       !is.na(ASTDT) & !is.na(TRTSDT) & ASTDT >= TRTSDT,       \"Y\",       NA_character_     )   ) |>   # Derive analysis variables   mutate(     AOCCPFL = if_else(AESEQ == min(AESEQ), \"Y\", NA_character_),     AOCC01FL = AOCCPFL   ) |>   group_by(USUBJID, AEDECOD) |>   mutate(     AOCC01FL = if_else(row_number() == 1, \"Y\", NA_character_)   ) |>   ungroup()  # Store ADAE in the data lake with_transaction(   create_table(adae, \"adae\"),   author = \"T Gerke\",   commit_message = \"Create ADAE dataset\",   commit_extra_info = \"Includes treatment-emergent flags and occurrence flags\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Preview ADAE get_ducklake_table(\"adae\") |>   filter(TRTEMFL == \"Y\") |>   select(USUBJID, AEDECOD, ASTDT, AESEV, TRTEMFL) |>   head(10) #> # Source:   SQL [?? x 5] #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #>    USUBJID     AEDECOD                              ASTDT      AESEV    TRTEMFL #>    <chr>       <chr>                                <date>     <chr>    <chr>   #>  1 01-701-1015 APPLICATION SITE ERYTHEMA            2014-01-03 MILD     Y       #>  2 01-701-1015 APPLICATION SITE PRURITUS            2014-01-03 MILD     Y       #>  3 01-701-1015 DIARRHOEA                            2014-01-09 MILD     Y       #>  4 01-701-1023 ATRIOVENTRICULAR BLOCK SECOND DEGREE 2012-08-26 MILD     Y       #>  5 01-701-1023 ERYTHEMA                             2012-08-07 MILD     Y       #>  6 01-701-1023 ERYTHEMA                             2012-08-07 MODERATE Y       #>  7 01-701-1023 ERYTHEMA                             2012-08-07 MILD     Y       #>  8 01-701-1028 APPLICATION SITE ERYTHEMA            2013-07-21 MILD     Y       #>  9 01-701-1028 APPLICATION SITE PRURITUS            2013-08-08 MILD     Y       #> 10 01-701-1034 APPLICATION SITE PRURITUS            2014-08-27 MILD     Y"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"adpc-pharmacokinetic-concentrations-analysis-dataset","dir":"Articles","previous_headings":"Building the Analytics Layer: ADaM Datasets (Gold Layer)","what":"ADPC: Pharmacokinetic Concentrations Analysis Dataset","title":"Clinical Trial Data Lake with ducklake","text":"ADPC supports non-compartmental analysis combining PK concentrations dosing records.","code":"# Read required datasets adsl <- get_ducklake_table(\"adsl\") |> collect() pc <- get_ducklake_table(\"pc\") |> collect() ex <- get_ducklake_table(\"ex\") |> collect() vs <- get_ducklake_table(\"vs\") |> collect()  # Get ADSL variables needed adsl_vars <- exprs(TRTSDT, TRTSDTM, TRT01P, TRT01A)  # Derive PC dates and times pc_dates <- pc |>   derive_vars_merged(     dataset_add = adsl,     new_vars = adsl_vars,     by_vars = exprs(STUDYID, USUBJID)   ) |>   derive_vars_dtm(     new_vars_prefix = \"A\",     dtc = PCDTC,     time_imputation = \"00:00:00\",     ignore_seconds_flag = FALSE   ) |>   derive_vars_dtm_to_dt(exprs(ADTM)) |>   derive_vars_dtm_to_tm(exprs(ADTM)) |>   derive_vars_dy(reference_date = TRTSDT, source_vars = exprs(ADT)) |>   mutate(     EVID = 0,     NFRLT = if_else(PCTPTNUM < 0, 0, PCTPTNUM)   )  # Process exposure records ex_dates <- ex |>   derive_vars_merged(     dataset_add = adsl,     new_vars = adsl_vars,     by_vars = exprs(STUDYID, USUBJID)   ) |>   filter(EXDOSE > 0) |>   derive_vars_dtm(     new_vars_prefix = \"AST\",     dtc = EXSTDTC,     time_imputation = \"00:00:00\"   ) |>   mutate(     EVID = 1,     NFRLT = 24 * VISITDY   ) |>   derive_vars_dtm_to_dt(exprs(ASTDTM))  # Combine PC and EX adpc <- bind_rows(pc_dates, ex_dates) |>   arrange(STUDYID, USUBJID, ADTM) |>   mutate(     PARAMCD = coalesce(PCTESTCD, \"DOSE\"),     AVAL = case_when(       EVID == 1 ~ EXDOSE,       PCSTRESC == \"<BLQ\" & NFRLT == 0 ~ 0,       PCSTRESC == \"<BLQ\" & NFRLT > 0 ~ 0.5 * PCLLOQ,       TRUE ~ PCSTRESN     ),     PARAM = case_when(       PARAMCD == \"XAN\" ~ \"Xanomeline Concentration\",       PARAMCD == \"DOSE\" ~ \"Xanomeline Dose\"     )   )  # Store ADPC in the data lake with_transaction(   create_table(adpc, \"adpc\"),   author = \"T Gerke\",   commit_message = \"Create ADPC dataset\",   commit_extra_info = \"PK concentrations with dosing records for NCA\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Preview ADPC get_ducklake_table(\"adpc\") |>   filter(PARAMCD == \"XAN\") |>   select(USUBJID, ADT, PCTPT, AVAL, PARAM) |>   head(10) #> # Source:   SQL [?? x 5] #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #>    USUBJID     ADT        PCTPT             AVAL PARAM                    #>    <chr>       <date>     <chr>            <dbl> <chr>                    #>  1 01-701-1015 2014-01-01 Pre-dose         0     Xanomeline Concentration #>  2 01-701-1015 2014-01-02 5 Min Post-dose  0.005 Xanomeline Concentration #>  3 01-701-1015 2014-01-02 30 Min Post-dose 0.005 Xanomeline Concentration #>  4 01-701-1015 2014-01-02 1h Post-dose     0.005 Xanomeline Concentration #>  5 01-701-1015 2014-01-02 1.5h Post-dose   0.005 Xanomeline Concentration #>  6 01-701-1015 2014-01-02 2h Post-dose     0.005 Xanomeline Concentration #>  7 01-701-1015 2014-01-02 4h Post-dose     0.005 Xanomeline Concentration #>  8 01-701-1015 2014-01-02 6h Post-dose     0.005 Xanomeline Concentration #>  9 01-701-1015 2014-01-02 0-6h Post-dose   0.005 Xanomeline Concentration #> 10 01-701-1015 2014-01-02 8h Post-dose     0.005 Xanomeline Concentration"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"storing-regulatory-submission-artifacts","dir":"Articles","previous_headings":"","what":"Storing Regulatory Submission Artifacts","title":"Clinical Trial Data Lake with ducklake","text":"Beyond datasets, regulatory submissions require metadata documentation. data lake can store various types artifacts including define.xml files structured data:","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"define-xml-metadata","dir":"Articles","previous_headings":"Storing Regulatory Submission Artifacts","what":"Define.xml Metadata","title":"Clinical Trial Data Lake with ducklake","text":"define.xml file provides dataset variable-level metadata required regulatory submissions. Store versioned artifact:","code":"# Example: Store define.xml content # In practice, you might read this from a file generated by your metadata system define_xml <- '<?xml version=\"1.0\" encoding=\"UTF-8\"?> <ODM xmlns=\"http://www.cdisc.org/ns/odm/v1.3\">   <!-- Define.xml content for ADSL, ADAE, ADPC datasets --> <\/ODM>'  # Create a table for regulatory documents regulatory_docs <- tibble(   doc_type = \"define.xml\",   doc_version = \"1.0\",   content = define_xml,   created_date = Sys.Date(),   description = \"Dataset and variable metadata for regulatory submission\" )  with_transaction(   create_table(regulatory_docs, \"regulatory_documents\"),   author = \"T Gerke\",   commit_message = \"Add define.xml metadata\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  get_ducklake_table(\"regulatory_documents\") #> # Source:   table<regulatory_documents> [?? x 5] #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #>   doc_type   doc_version content                        created_date description #>   <chr>      <chr>       <chr>                          <date>       <chr>       #> 1 define.xml 1.0         \"<?xml version=\\\"1.0\\\" encodi… 2026-02-06   Dataset an…"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"storing-different-data-types-json-example","dir":"Articles","previous_headings":"Storing Regulatory Submission Artifacts","what":"Storing Different Data Types (JSON Example)","title":"Clinical Trial Data Lake with ducklake","text":"Analysis Results Metadata (ARM) Analysis Results Data (ARD) might stored separate data tables practice, example demonstrates store structured data JSON format within data lake:","code":"# Example: Store Analysis Results Metadata (ARM) arm_content <- tibble(   analysis_id = \"DEMO01\",   analysis_name = \"Demographics Table\",   dataset_used = \"ADSL\",   program_name = \"t_demographics.R\",   output_file = \"t_demographics.rtf\",   analysis_date = Sys.Date() )  # Add to or update regulatory documents table with_transaction(   get_ducklake_table(\"regulatory_documents\") |>     collect() |>     mutate(content = as.character(content)) |>     bind_rows(       tibble(         doc_type = \"ARM\",         doc_version = \"1.0\",         content = as.character(jsonlite::toJSON(arm_content)),         created_date = Sys.Date(),         description = \"Analysis Results Metadata\"       )     ) |>     distinct(doc_type, doc_version, .keep_all = TRUE) |>     replace_table(\"regulatory_documents\"),   author = \"T Gerke\",   commit_message = \"Add ARM metadata\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Example: Store Analysis Results Data (ARD) ard_content <- tibble(   analysis_id = \"DEMO01\",   row_type = \"header\",   row_label = \"Age (years)\",   treatment = c(\"Placebo\", \"Xanomeline Low\", \"Xanomeline High\"),   n = c(86, 84, 84),   mean = c(75.2, 75.7, 74.4),   sd = c(8.59, 7.89, 7.89) )  with_transaction(   get_ducklake_table(\"regulatory_documents\") |>     collect() |>     mutate(content = as.character(content)) |>     bind_rows(       tibble(         doc_type = \"ARD\",         doc_version = \"1.0\",         content = as.character(jsonlite::toJSON(ard_content)),         created_date = Sys.Date(),         description = \"Analysis Results Data for Demographics Table\"       )     ) |>     distinct(doc_type, doc_version, .keep_all = TRUE) |>     replace_table(\"regulatory_documents\"),   author = \"T Gerke\",   commit_message = \"Add demographics ARD\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"dataset-specifications","dir":"Articles","previous_headings":"Storing Regulatory Submission Artifacts","what":"Dataset Specifications","title":"Clinical Trial Data Lake with ducklake","text":"Store dataset specifications alongside data: unified approach ensures submission artifacts version-controlled alongside datasets describe, maintaining perfect alignment data documentation.","code":"# Example: Store ADSL specifications adsl_spec <- tibble(   dataset = \"ADSL\",   variable = c(\"USUBJID\", \"AGE\", \"AGEGR1\", \"TRT01P\", \"SAFFL\"),   label = c(     \"Unique Subject Identifier\",     \"Age\",     \"Age Group 1\",     \"Planned Treatment\",     \"Safety Population Flag\"   ),   type = c(\"text\", \"num\", \"text\", \"text\", \"text\"),   length = c(20, 8, 10, 40, 1),   derivation = c(\"DM.USUBJID\", \"DM.AGE\", \"Derived from AGE\", \"DM.ARM\", \"Derived\") )  with_transaction(   create_table(adsl_spec, \"dataset_specifications\"),   author = \"T Gerke\",   commit_message = \"Add ADSL specifications\" )  # Query specifications when needed get_ducklake_table(\"dataset_specifications\") |>   filter(dataset == \"ADSL\")"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"organizational-structure-and-cohesion","dir":"Articles","previous_headings":"","what":"Organizational Structure and Cohesion","title":"Clinical Trial Data Lake with ducklake","text":"One key advantages data lake approach preserves leverages inherently relational structure CDISC data.","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"relational-structure-beyond-flat-files","dir":"Articles","previous_headings":"Organizational Structure and Cohesion","what":"Relational Structure: Beyond Flat Files","title":"Clinical Trial Data Lake with ducklake","text":"Many clinical trial workflows store SDTM domain ADaM dataset separate flat files (XPT, SAS7BDAT, CSV). meets regulatory requirements submission formats, often loses relational structure inherent CDISC standards day--day analysis work. Every SDTM domain shares STUDYID USUBJID keys, domains explicitly designed relate (e.g., EX records link DM subjects, AE records link DM EX). organizations use SAS datasets databases database solutions, DuckLake provides R-native approach preserves relationships version control built :","code":"# Traditional approach: Load multiple files, manually join # adsl <- read_xpt(\"adsl.xpt\") # ex <- read_xpt(\"ex.xpt\") # ae <- read_xpt(\"ae.xpt\") # result <- adsl |> left_join(ex, ...) |> left_join(ae, ...)  # DuckLake approach: Query across related tables directly using dplyr # Complex cross-domain query without loading all data adsl_tbl <- get_ducklake_table(\"adsl\") ex_tbl <- get_ducklake_table(\"ex\") ae_tbl <- get_ducklake_table(\"ae\")  adsl_tbl |>   filter(SAFFL == \"Y\") |>   left_join(ex_tbl, by = \"USUBJID\") |>   left_join(ae_tbl, by = \"USUBJID\") |>   group_by(USUBJID, AGE, TRT01P) |>   summarise(     n_aes = n_distinct(AESEQ, na.rm = TRUE),     total_dose = sum(EXDOSE, na.rm = TRUE),     .groups = \"drop\"   ) |>   arrange(desc(n_aes)) |>   head(10) |>   collect() #> # A tibble: 10 × 5 #>    USUBJID       AGE TRT01P               n_aes total_dose #>    <chr>       <dbl> <chr>                <dbl>      <dbl> #>  1 01-701-1302    61 Xanomeline High Dose    23       3105 #>  2 01-717-1004    80 Xanomeline Low Dose     19       3078 #>  3 01-709-1029    82 Xanomeline High Dose    16       3024 #>  4 01-704-1266    82 Xanomeline High Dose    16       2160 #>  5 01-718-1427    74 Xanomeline High Dose    16       2160 #>  6 01-713-1179    64 Placebo                 15          0 #>  7 01-709-1309    65 Xanomeline High Dose    15       2835 #>  8 01-701-1275    61 Xanomeline High Dose    15       2025 #>  9 01-701-1192    80 Xanomeline Low Dose     15       2430 #> 10 01-711-1143    76 Xanomeline Low Dose     14       1512"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"data-warehouse-benefits","dir":"Articles","previous_headings":"Organizational Structure and Cohesion","what":"Data Warehouse Benefits","title":"Clinical Trial Data Lake with ducklake","text":"approach provides traditional data warehouse capabilities clinical trials:","code":"# 1. Single source of truth - all datasets in one repository # List all tables in the data lake DBI::dbListTables(duckplyr:::get_default_duckdb_connection()) #>  [1] \"adae\"                                  #>  [2] \"adpc\"                                  #>  [3] \"adsl\"                                  #>  [4] \"ae\"                                    #>  [5] \"ae_raw\"                                #>  [6] \"dm\"                                    #>  [7] \"dm_raw\"                                #>  [8] \"ds\"                                    #>  [9] \"ds_raw\"                                #> [10] \"ducklake_column\"                       #> [11] \"ducklake_column_mapping\"               #> [12] \"ducklake_column_tag\"                   #> [13] \"ducklake_data_file\"                    #> [14] \"ducklake_delete_file\"                  #> [15] \"ducklake_file_column_stats\"            #> [16] \"ducklake_file_partition_value\"         #> [17] \"ducklake_files_scheduled_for_deletion\" #> [18] \"ducklake_inlined_data_tables\"          #> [19] \"ducklake_metadata\"                     #> [20] \"ducklake_name_mapping\"                 #> [21] \"ducklake_partition_column\"             #> [22] \"ducklake_partition_info\"               #> [23] \"ducklake_schema\"                       #> [24] \"ducklake_schema_versions\"              #> [25] \"ducklake_snapshot\"                     #> [26] \"ducklake_snapshot_changes\"             #> [27] \"ducklake_table\"                        #> [28] \"ducklake_table_column_stats\"           #> [29] \"ducklake_table_stats\"                  #> [30] \"ducklake_tag\"                          #> [31] \"ducklake_view\"                         #> [32] \"ex\"                                    #> [33] \"ex_raw\"                                #> [34] \"pc\"                                    #> [35] \"pc_raw\"                                #> [36] \"regulatory_documents\"                  #> [37] \"suppdm\"                                #> [38] \"suppdm_raw\"                            #> [39] \"vs\"                                    #> [40] \"vs_raw\"  # 2. Efficient filtering before loading into R # Only load subjects with adverse events get_ducklake_table(\"ae\") |>   filter(AESEV == \"SEVERE\") |>   distinct(USUBJID) #> # Source:   SQL [?? x 1] #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #>    USUBJID     #>    <chr>       #>  1 01-703-1086 #>  2 01-703-1119 #>  3 01-706-1049 #>  4 01-708-1428 #>  5 01-710-1083 #>  6 01-718-1079 #>  7 01-718-1170 #>  8 01-704-1008 #>  9 01-704-1445 #> 10 01-710-1070 #> # ℹ more rows  # 3. Aggregations performed at database level get_ducklake_table(\"adae\") |>   filter(TRTEMFL == \"Y\") |>   group_by(TRT01A, AESEV) |>   summarise(     n_events = n(),     n_subjects = n_distinct(USUBJID),     .groups = \"drop\"   ) #> # Source:   SQL [?? x 4] #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #>   TRT01A               AESEV    n_events n_subjects #>   <chr>                <chr>       <dbl>      <dbl> #> 1 Placebo              MILD          210         58 #> 2 Xanomeline High Dose SEVERE         10          8 #> 3 Placebo              MODERATE       65         25 #> 4 Xanomeline Low Dose  SEVERE         25         16 #> 5 Xanomeline Low Dose  MILD          232         64 #> 6 Xanomeline High Dose MODERATE      115         46 #> 7 Xanomeline High Dose MILD          287         65 #> 8 Xanomeline Low Dose  MODERATE      170         58 #> 9 Placebo              SEVERE          6          5  # 4. Joins across SDTM and ADaM layers # Example: Find date discrepancies between SDTM and ADaM ae_sdtm <- get_ducklake_table(\"ae\") |>   select(USUBJID, AESEQ, ae_date = AESTDTC, ae_term = AEDECOD)  adae_adam <- get_ducklake_table(\"adae\") |>   select(USUBJID, AESEQ, adae_date = ASTDT, adae_term = AEDECOD)  ae_sdtm |>   inner_join(adae_adam, by = c(\"USUBJID\", \"AESEQ\")) |>   # Convert SDTM character date to comparable format for filtering   mutate(ae_date_comparable = substr(ae_date, 1, 10)) |>   filter(ae_date_comparable != as.character(adae_date)) |>   select(     USUBJID,     sdtm_start_date = ae_date,     adam_start_date = adae_date,     sdtm_term = ae_term,     adam_term = adae_term   ) #> # Source:   SQL [?? x 5] #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #> # ℹ 5 variables: USUBJID <chr>, sdtm_start_date <chr>, adam_start_date <date>, #> #   sdtm_term <chr>, adam_term <chr> # Note: This returns 0 rows with clean pharmaversesdtm data, # but demonstrates how to check for data quality issues across layers"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"cohesive-dataset-relationships","dir":"Articles","previous_headings":"Organizational Structure and Cohesion","what":"Cohesive Dataset Relationships","title":"Clinical Trial Data Lake with ducklake","text":"Let’s explore datasets connected: relational approach means clinical trial data lake functions purpose-built data warehouse, designed specifically relational nature CDISC standards.","code":"# List all tables in the data lake DBI::dbListTables(duckplyr:::get_default_duckdb_connection()) #>  [1] \"adae\"                                  #>  [2] \"adpc\"                                  #>  [3] \"adsl\"                                  #>  [4] \"ae\"                                    #>  [5] \"ae_raw\"                                #>  [6] \"dm\"                                    #>  [7] \"dm_raw\"                                #>  [8] \"ds\"                                    #>  [9] \"ds_raw\"                                #> [10] \"ducklake_column\"                       #> [11] \"ducklake_column_mapping\"               #> [12] \"ducklake_column_tag\"                   #> [13] \"ducklake_data_file\"                    #> [14] \"ducklake_delete_file\"                  #> [15] \"ducklake_file_column_stats\"            #> [16] \"ducklake_file_partition_value\"         #> [17] \"ducklake_files_scheduled_for_deletion\" #> [18] \"ducklake_inlined_data_tables\"          #> [19] \"ducklake_metadata\"                     #> [20] \"ducklake_name_mapping\"                 #> [21] \"ducklake_partition_column\"             #> [22] \"ducklake_partition_info\"               #> [23] \"ducklake_schema\"                       #> [24] \"ducklake_schema_versions\"              #> [25] \"ducklake_snapshot\"                     #> [26] \"ducklake_snapshot_changes\"             #> [27] \"ducklake_table\"                        #> [28] \"ducklake_table_column_stats\"           #> [29] \"ducklake_table_stats\"                  #> [30] \"ducklake_tag\"                          #> [31] \"ducklake_view\"                         #> [32] \"ex\"                                    #> [33] \"ex_raw\"                                #> [34] \"pc\"                                    #> [35] \"pc_raw\"                                #> [36] \"regulatory_documents\"                  #> [37] \"suppdm\"                                #> [38] \"suppdm_raw\"                            #> [39] \"vs\"                                    #> [40] \"vs_raw\"  # View snapshot history for key tables metadata_tables <- c(\"dm\", \"ex\", \"ae\", \"pc\",                       \"adsl\", \"adae\", \"adpc\")  # Collect snapshots for all tables purrr::map_dfr(metadata_tables, ~{   list_table_snapshots(.x) |>     mutate(table = .x, .before = 1) }) |>   select(table, snapshot_id, snapshot_time, changes) #>   table snapshot_id       snapshot_time #> 1    dm           2 2026-02-06 20:34:32 #> 2    ex           8 2026-02-06 20:34:32 #> 3    ae          10 2026-02-06 20:34:33 #> 4    pc          14 2026-02-06 20:34:33 #> 5  adsl          15 2026-02-06 20:34:34 #> 6  adae          16 2026-02-06 20:34:35 #> 7  adpc          17 2026-02-06 20:34:35 #>                                               changes #> 1    tables_created, tables_inserted_into, main.dm, 2 #> 2    tables_created, tables_inserted_into, main.ex, 8 #> 3   tables_created, tables_inserted_into, main.ae, 10 #> 4   tables_created, tables_inserted_into, main.pc, 14 #> 5 tables_created, tables_inserted_into, main.adsl, 15 #> 6 tables_created, tables_inserted_into, main.adae, 16 #> 7 tables_created, tables_inserted_into, main.adpc, 17  # Check all ADAE subjects exist in ADSL adae_tbl <- get_ducklake_table(\"adae\") adsl_tbl <- get_ducklake_table(\"adsl\")  integrity_check <- adae_tbl |>   anti_join(adsl_tbl, by = \"USUBJID\") |>   summarise(orphaned_records = n()) |>   collect()  # ADAE records without ADSL subject: integrity_check |> pull(orphaned_records) #> [1] 0"},{"path":[]},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"version-control-and-snapshots","dir":"Articles","previous_headings":"Demonstrating Core Functionality","what":"Version Control and Snapshots","title":"Clinical Trial Data Lake with ducklake","text":"Every modification tables automatically versioned. Let’s demonstrate adding new derived variables ADSL:","code":"# Add new derived columns using dplyr syntax # replace_table() handles the DROP/CREATE cycle internally with_transaction(   get_ducklake_table(\"adsl\") |>     mutate(       AGE65FL = if_else(AGE >= 65, \"Y\", \"N\"),       AGECAT = case_when(         AGE < 65 ~ \"<65\",         AGE >= 65 & AGE < 75 ~ \"65-74\",         AGE >= 75 ~ \">=75\",         TRUE ~ NA_character_       )     ) |>     replace_table(\"adsl\"),   author = \"T Gerke\",   commit_message = \"Add age categorization vars\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # View version history - should now show 2 snapshots list_table_snapshots(\"adsl\") #>    snapshot_id       snapshot_time schema_version #> 16          15 2026-02-06 20:34:34             15 #> 22          21 2026-02-06 20:34:37             21 #>                                                                    changes #> 16                     tables_created, tables_inserted_into, main.adsl, 15 #> 22 tables_created, tables_dropped, tables_inserted_into, main.adsl, 15, 21 #>     author              commit_message #> 16 T Gerke         Create ADSL dataset #> 22 T Gerke Add age categorization vars #>                                                                      commit_extra_info #> 16 Derived from DM, SUPPDM, DS, EX; includes treatment dates, safety flags, age groups #> 22                                                                                <NA>  # Verify new columns exist get_ducklake_table(\"adsl\") |>   select(USUBJID, AGE, AGE65FL, AGECAT) |>   head(5) #> # Source:   SQL [?? x 4] #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #>   USUBJID       AGE AGE65FL AGECAT #>   <chr>       <dbl> <chr>   <chr>  #> 1 01-701-1015    63 N       <65    #> 2 01-701-1023    64 N       <65    #> 3 01-701-1028    71 Y       65-74  #> 4 01-701-1033    74 Y       65-74  #> 5 01-701-1034    77 Y       >=75"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"choosing-between-replace_table-and-update_table","dir":"Articles","previous_headings":"Demonstrating Core Functionality > Version Control and Snapshots","what":"Choosing Between replace_table() and update_table()","title":"Clinical Trial Data Lake with ducklake","text":"ducklake package provides two functions modifying tables, optimized different use cases: Use replace_table() : Adding removing columns - DuckLake UPDATE operations can modify existing column values, change schema want versioning - Creates new snapshot via DROP + CREATE, enabling time travel previous schemas Making bulk transformations - Efficient applying complex dplyr pipelines restructure data Working dplyr pipelines - Provides natural dplyr-like interface: get_ducklake_table(name) |> mutate(...) |> replace_table(name) Use update_table() : Non-GxP workflows - Data pipelines regulatory audit trails required Never clinical trial submission datasets - lack audit trail creates regulatory compliance gaps ⚠️ Critical Clinical Trials: update_table() appropriate GxP-validated work. permanently modifies tables without creating snapshots audit trails, violating regulatory requirements (21 CFR Part 11, ICH GCP): ❌ Changes time-traveled back ❌ record values changed ❌ prove data integrity regulatory inspections ❌ Violates requirement complete data lineage Recommendation: clinical trial data, default replace_table() modifications, matter minor. audit trail important avoiding “version clutter.” GxP-compliant workflows, use replace_table() changes ensure complete audit trails ability recreate previous states. Note versioning: transactions (begin_transaction()/commit_transaction()) ensure atomic operations, CREATE operations trigger snapshot creation. UPDATE operations modify tables -place without snapshots, regardless transaction context. Bottom line clinical trials: change matters enough make, matters enough audit. Use replace_table() wrapped transaction data modification - whether correcting single value adding new columns: operations create snapshots can time-travel back include regulatory audit trail.","code":"# Correcting a specific value - creates auditable snapshot with_transaction(   get_ducklake_table(\"adsl\") |>     mutate(SAFFL = if_else(USUBJID == \"01-701-1015\", \"N\", SAFFL)) |>     replace_table(\"adsl\"),   author = \"T Gerke\",   commit_message = \"Correct safety flag\" )  # Adding new derived columns - creates auditable snapshot with_transaction(   get_ducklake_table(\"adsl\") |>     mutate(AGE65FL = if_else(AGE >= 65, \"Y\", \"N\")) |>     replace_table(\"adsl\"),   author = \"T Gerke\",   commit_message = \"Add age 65+ flag\" )"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"iterative-development-with-full-audit-trail","dir":"Articles","previous_headings":"Demonstrating Core Functionality > Version Control and Snapshots","what":"Iterative Development with Full Audit Trail","title":"Clinical Trial Data Lake with ducklake","text":"developing derivations, create snapshot meaningful iteration maintain complete audit trail: GxP-compliant approach ensures: Complete audit trail derivation iterations Ability recreate intermediate state Proof changed regulatory inspections Data lineage initial final derivation","code":"# Iteration 1: First attempt (creates snapshot v2) with_transaction(   get_ducklake_table(\"adsl\") |>     mutate(AGECAT_TEST = case_when(       AGE < 50 ~ \"Young\",       AGE >= 50 ~ \"Older\"     )) |>     replace_table(\"adsl\"),   author = \"T Gerke\",   commit_message = \"Test age categories v1\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Iteration 2: Refinement (creates snapshot v3) with_transaction(   get_ducklake_table(\"adsl\") |>     mutate(AGECAT_TEST = case_when(       AGE < 40 ~ \"18-39\",       AGE < 65 ~ \"40-64\",       AGE >= 65 ~ \"65+\"     )) |>     replace_table(\"adsl\"),   author = \"T Gerke\",   commit_message = \"Refine age categories v2\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Iteration 3: Final version (creates snapshot v4) with_transaction(   get_ducklake_table(\"adsl\") |>     mutate(       AGECAT_TEST = NULL,       AGECAT2 = case_when(         AGE < 40 ~ \"18-39\",         AGE < 65 ~ \"40-64\",         AGE >= 65 ~ \"65+\",         TRUE ~ \"Missing\"       )     ) |>     replace_table(\"adsl\"),   author = \"T Gerke\",   commit_message = \"Finalize age categories\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Complete audit trail available snapshots <- list_table_snapshots(\"adsl\") snapshots  # Shows all iterations with snapshot metadata #>    snapshot_id       snapshot_time schema_version #> 16          15 2026-02-06 20:34:34             15 #> 22          21 2026-02-06 20:34:37             21 #> 23          22 2026-02-06 20:34:37             22 #> 24          23 2026-02-06 20:34:37             23 #> 25          24 2026-02-06 20:34:37             24 #>                                                                    changes #> 16                     tables_created, tables_inserted_into, main.adsl, 15 #> 22 tables_created, tables_dropped, tables_inserted_into, main.adsl, 15, 21 #> 23 tables_created, tables_dropped, tables_inserted_into, main.adsl, 21, 22 #> 24 tables_created, tables_dropped, tables_inserted_into, main.adsl, 22, 23 #> 25 tables_created, tables_dropped, tables_inserted_into, main.adsl, 23, 24 #>     author              commit_message #> 16 T Gerke         Create ADSL dataset #> 22 T Gerke Add age categorization vars #> 23 T Gerke      Test age categories v1 #> 24 T Gerke    Refine age categories v2 #> 25 T Gerke     Finalize age categories #>                                                                      commit_extra_info #> 16 Derived from DM, SUPPDM, DS, EX; includes treatment dates, safety flags, age groups #> 22                                                                                <NA> #> 23                                                                                <NA> #> 24                                                                                <NA> #> 25                                                                                <NA>  # Each row represents a point in time you can restore to # - snapshot_id: Unique identifier for this version # - snapshot_time: When this version was created # - changes: What operations created this snapshot  # Time-travel to specific snapshots using snapshot_id # Use actual snapshot IDs from the list (first, second, and last) snapshot_ids <- snapshots$snapshot_id adsl_v1 <- get_ducklake_table_version(\"adsl\", snapshot_ids[1]) adsl_v2 <- get_ducklake_table_version(\"adsl\", snapshot_ids[2]) adsl_final <- get_ducklake_table_version(\"adsl\", snapshot_ids[length(snapshot_ids)])  # Or use snapshot times for time-travel adsl_asof <- get_ducklake_table_asof(\"adsl\", snapshots$snapshot_time[2])  # Compare columns across iterations colnames(adsl_v1 |> collect())  # Initial version #>  [1] \"STUDYID\"  \"DOMAIN\"   \"USUBJID\"  \"SUBJID\"   \"RFSTDTC\"  \"RFENDTC\"  #>  [7] \"RFXSTDTC\" \"RFXENDTC\" \"RFICDTC\"  \"RFPENDTC\" \"DTHDTC\"   \"DTHFL\"    #> [13] \"SITEID\"   \"BRTHDTC\"  \"AGE\"      \"AGEU\"     \"SEX\"      \"RACE\"     #> [19] \"ETHNIC\"   \"ARMCD\"    \"ARM\"      \"ACTARMCD\" \"ACTARM\"   \"COUNTRY\"  #> [25] \"DMDTC\"    \"DMDY\"     \"TRTSDTM\"  \"TRTEDTM\"  \"TRTSDT\"   \"TRTEDT\"   #> [31] \"TRTDURD\"  \"SAFFL\"    \"TRT01P\"   \"TRT01A\"   \"AGEGR1\"   \"AGEGR1N\"  #> [37] \"RANDDT\"   \"EOSDT\"    \"EOSSTT\" colnames(adsl_final |> collect())  # Final version with all derivations #>  [1] \"STUDYID\"  \"DOMAIN\"   \"USUBJID\"  \"SUBJID\"   \"RFSTDTC\"  \"RFENDTC\"  #>  [7] \"RFXSTDTC\" \"RFXENDTC\" \"RFICDTC\"  \"RFPENDTC\" \"DTHDTC\"   \"DTHFL\"    #> [13] \"SITEID\"   \"BRTHDTC\"  \"AGE\"      \"AGEU\"     \"SEX\"      \"RACE\"     #> [19] \"ETHNIC\"   \"ARMCD\"    \"ARM\"      \"ACTARMCD\" \"ACTARM\"   \"COUNTRY\"  #> [25] \"DMDTC\"    \"DMDY\"     \"TRTSDTM\"  \"TRTEDTM\"  \"TRTSDT\"   \"TRTEDT\"   #> [31] \"TRTDURD\"  \"SAFFL\"    \"TRT01P\"   \"TRT01A\"   \"AGEGR1\"   \"AGEGR1N\"  #> [37] \"RANDDT\"   \"EOSDT\"    \"EOSSTT\"   \"AGE65FL\"  \"AGECAT\"   \"AGECAT2\""},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"time-travel","dir":"Articles","previous_headings":"Demonstrating Core Functionality","what":"Time Travel","title":"Clinical Trial Data Lake with ducklake","text":"Query data existed specific point time:","code":"# Get the current version adsl_current <- get_ducklake_table(\"adsl\")  # Get the version history for adsl versions <- list_table_snapshots(\"adsl\") print(versions) #>    snapshot_id       snapshot_time schema_version #> 16          15 2026-02-06 20:34:34             15 #> 22          21 2026-02-06 20:34:37             21 #> 23          22 2026-02-06 20:34:37             22 #> 24          23 2026-02-06 20:34:37             23 #> 25          24 2026-02-06 20:34:37             24 #>                                                                    changes #> 16                     tables_created, tables_inserted_into, main.adsl, 15 #> 22 tables_created, tables_dropped, tables_inserted_into, main.adsl, 15, 21 #> 23 tables_created, tables_dropped, tables_inserted_into, main.adsl, 21, 22 #> 24 tables_created, tables_dropped, tables_inserted_into, main.adsl, 22, 23 #> 25 tables_created, tables_dropped, tables_inserted_into, main.adsl, 23, 24 #>     author              commit_message #> 16 T Gerke         Create ADSL dataset #> 22 T Gerke Add age categorization vars #> 23 T Gerke      Test age categories v1 #> 24 T Gerke    Refine age categories v2 #> 25 T Gerke     Finalize age categories #>                                                                      commit_extra_info #> 16 Derived from DM, SUPPDM, DS, EX; includes treatment dates, safety flags, age groups #> 22                                                                                <NA> #> 23                                                                                <NA> #> 24                                                                                <NA> #> 25                                                                                <NA>  # Get data from the first snapshot version first_snapshot_id <- versions |>   slice(1) |>   pull(snapshot_id)  adsl_v1 <- get_ducklake_table_version(   table_name = \"adsl\",   version = first_snapshot_id )  # Compare versions - earlier version shouldn't have derived variables added later adsl_v1 |> collect() #> # A tibble: 306 × 39 #>    STUDYID      DOMAIN USUBJID  SUBJID RFSTDTC RFENDTC RFXSTDTC RFXENDTC RFICDTC #>    <chr>        <chr>  <chr>    <chr>  <chr>   <chr>   <chr>    <chr>    <chr>   #>  1 CDISCPILOT01 DM     01-701-… 1015   2014-0… 2014-0… 2014-01… 2014-07… NA      #>  2 CDISCPILOT01 DM     01-701-… 1023   2012-0… 2012-0… 2012-08… 2012-09… NA      #>  3 CDISCPILOT01 DM     01-701-… 1028   2013-0… 2014-0… 2013-07… 2014-01… NA      #>  4 CDISCPILOT01 DM     01-701-… 1033   2014-0… 2014-0… 2014-03… 2014-03… NA      #>  5 CDISCPILOT01 DM     01-701-… 1034   2014-0… 2014-1… 2014-07… 2014-12… NA      #>  6 CDISCPILOT01 DM     01-701-… 1047   2013-0… 2013-0… 2013-02… 2013-03… NA      #>  7 CDISCPILOT01 DM     01-701-… 1057   NA      NA      NA       NA       NA      #>  8 CDISCPILOT01 DM     01-701-… 1097   2014-0… 2014-0… 2014-01… 2014-07… NA      #>  9 CDISCPILOT01 DM     01-701-… 1111   2012-0… 2012-0… 2012-09… 2012-09… NA      #> 10 CDISCPILOT01 DM     01-701-… 1115   2012-1… 2013-0… 2012-11… 2013-01… NA      #> # ℹ 296 more rows #> # ℹ 30 more variables: RFPENDTC <chr>, DTHDTC <chr>, DTHFL <chr>, SITEID <chr>, #> #   BRTHDTC <chr>, AGE <dbl>, AGEU <chr>, SEX <chr>, RACE <chr>, ETHNIC <chr>, #> #   ARMCD <chr>, ARM <chr>, ACTARMCD <chr>, ACTARM <chr>, COUNTRY <chr>, #> #   DMDTC <chr>, DMDY <dbl>, TRTSDTM <dttm>, TRTEDTM <dttm>, TRTSDT <date>, #> #   TRTEDT <date>, TRTDURD <dbl>, SAFFL <chr>, TRT01P <chr>, TRT01A <chr>, #> #   AGEGR1 <chr>, AGEGR1N <dbl>, RANDDT <date>, EOSDT <date>, EOSSTT <chr> adsl_current |> collect() #> # A tibble: 306 × 42 #>    STUDYID      DOMAIN USUBJID  SUBJID RFSTDTC RFENDTC RFXSTDTC RFXENDTC RFICDTC #>    <chr>        <chr>  <chr>    <chr>  <chr>   <chr>   <chr>    <chr>    <chr>   #>  1 CDISCPILOT01 DM     01-701-… 1015   2014-0… 2014-0… 2014-01… 2014-07… NA      #>  2 CDISCPILOT01 DM     01-701-… 1023   2012-0… 2012-0… 2012-08… 2012-09… NA      #>  3 CDISCPILOT01 DM     01-701-… 1028   2013-0… 2014-0… 2013-07… 2014-01… NA      #>  4 CDISCPILOT01 DM     01-701-… 1033   2014-0… 2014-0… 2014-03… 2014-03… NA      #>  5 CDISCPILOT01 DM     01-701-… 1034   2014-0… 2014-1… 2014-07… 2014-12… NA      #>  6 CDISCPILOT01 DM     01-701-… 1047   2013-0… 2013-0… 2013-02… 2013-03… NA      #>  7 CDISCPILOT01 DM     01-701-… 1057   NA      NA      NA       NA       NA      #>  8 CDISCPILOT01 DM     01-701-… 1097   2014-0… 2014-0… 2014-01… 2014-07… NA      #>  9 CDISCPILOT01 DM     01-701-… 1111   2012-0… 2012-0… 2012-09… 2012-09… NA      #> 10 CDISCPILOT01 DM     01-701-… 1115   2012-1… 2013-0… 2012-11… 2013-01… NA      #> # ℹ 296 more rows #> # ℹ 33 more variables: RFPENDTC <chr>, DTHDTC <chr>, DTHFL <chr>, SITEID <chr>, #> #   BRTHDTC <chr>, AGE <dbl>, AGEU <chr>, SEX <chr>, RACE <chr>, ETHNIC <chr>, #> #   ARMCD <chr>, ARM <chr>, ACTARMCD <chr>, ACTARM <chr>, COUNTRY <chr>, #> #   DMDTC <chr>, DMDY <dbl>, TRTSDTM <dttm>, TRTEDTM <dttm>, TRTSDT <date>, #> #   TRTEDT <date>, TRTDURD <dbl>, SAFFL <chr>, TRT01P <chr>, TRT01A <chr>, #> #   AGEGR1 <chr>, AGEGR1N <dbl>, RANDDT <date>, EOSDT <date>, EOSSTT <chr>, …"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"transactions-for-atomic-updates","dir":"Articles","previous_headings":"Demonstrating Core Functionality","what":"Transactions for Atomic Updates","title":"Clinical Trial Data Lake with ducklake","text":"Transactions ensure related table updates either succeed fail together, maintaining data consistency. critical adding derived variables must stay synchronized across datasets. ’s example adding new analysis flag ADSL ADAE atomically: ensures ADSL ADAE stay synchronized - either get new ANALYSISFL column neither . with_transaction() function automatically handles rollback operation fails, making safer manually managing transactions. updates also versioned audit trails.","code":"# Add ANALYSISFL to both ADSL and ADAE in a single atomic operation # with_transaction() automatically handles rollback on error with_transaction({   # First, add the flag to ADSL   get_ducklake_table(\"adsl\") |>     mutate(ANALYSISFL = if_else(SAFFL == \"Y\" & !is.na(TRTSDT), \"Y\", \"N\")) |>     replace_table(\"adsl\")  # Creates versioned snapshot      # Then propagate to ADAE by joining   adsl_flags <- get_ducklake_table(\"adsl\") |>     select(USUBJID, ANALYSISFL)      get_ducklake_table(\"adae\") |>     select(-any_of(\"ANALYSISFL\")) |>  # Remove if exists     left_join(adsl_flags, by = \"USUBJID\") |>     replace_table(\"adae\")  # Creates versioned snapshot      # Both updates succeed together   cat(\"Both tables updated successfully\\n\") }, author = \"T Gerke\", commit_message = \"Add analysis flag\") #> Transaction started #> Both tables updated successfully #> Transaction committed #> Snapshot metadata updated"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"updating-records","dir":"Articles","previous_headings":"Demonstrating Core Functionality","what":"Updating Records","title":"Clinical Trial Data Lake with ducklake","text":"Update existing records maintaining version control audit trails:","code":"# Update a specific record with versioning with_transaction(   get_ducklake_table(\"adae\") |>     mutate(       AESEV = if_else(         USUBJID == \"01-701-1015\" & AESEQ == 1,         \"SEVERE\",         AESEV       )     ) |>     replace_table(\"adae\"),  # Creates versioned snapshot   author = \"T Gerke\",   commit_message = \"Correct AE severity\" ) #> Transaction started #> Transaction committed #> Snapshot metadata updated  # Verify the update get_ducklake_table(\"adae\") |>   filter(USUBJID == \"01-701-1015\", AESEQ == 1) |>   select(USUBJID, AEDECOD, AESEV) #> # Source:   SQL [?? x 3] #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #>   USUBJID     AEDECOD                   AESEV  #>   <chr>       <chr>                     <chr>  #> 1 01-701-1015 APPLICATION SITE ERYTHEMA SEVERE"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"querying-and-analysis","dir":"Articles","previous_headings":"","what":"Querying and Analysis","title":"Clinical Trial Data Lake with ducklake","text":"data lake enables efficient querying across datasets:","code":"# Example 1: Subject disposition summary get_ducklake_table(\"adsl\") |>   count(EOSSTT, TRT01P) |>   arrange(TRT01P, EOSSTT) #> # Source:     SQL [?? x 3] #> # Database:   DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #> # Ordered by: TRT01P, EOSSTT #>   EOSSTT    TRT01P                   n #>   <chr>     <chr>                <dbl> #> 1 COMPLETED Placebo                 86 #> 2 ONGOING   Screen Failure          52 #> 3 COMPLETED Xanomeline High Dose    84 #> 4 COMPLETED Xanomeline Low Dose     84  # Example 2: Treatment-emergent AE summary by severity get_ducklake_table(\"adae\") |>   filter(TRTEMFL == \"Y\") |>   count(TRT01A, AESEV) |>   arrange(TRT01A, AESEV) #> # Source:     SQL [?? x 3] #> # Database:   DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #> # Ordered by: TRT01A, AESEV #>   TRT01A               AESEV        n #>   <chr>                <chr>    <dbl> #> 1 Placebo              MILD       209 #> 2 Placebo              MODERATE    65 #> 3 Placebo              SEVERE       7 #> 4 Xanomeline High Dose MILD       287 #> 5 Xanomeline High Dose MODERATE   115 #> 6 Xanomeline High Dose SEVERE      10 #> 7 Xanomeline Low Dose  MILD       232 #> 8 Xanomeline Low Dose  MODERATE   170 #> 9 Xanomeline Low Dose  SEVERE      25  # Example 3: PK concentration profile get_ducklake_table(\"adpc\") |>   filter(PARAMCD == \"XAN\", EVID == 0) |>   group_by(NFRLT) |>   summarise(     n = n(),     mean_conc = mean(AVAL, na.rm = TRUE),     sd_conc = sd(AVAL, na.rm = TRUE)   ) |>   arrange(NFRLT) #> # Source:     SQL [?? x 4] #> # Database:   DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #> # Ordered by: NFRLT #>    NFRLT     n mean_conc  sd_conc #>    <dbl> <dbl>     <dbl>    <dbl> #>  1  0      254   0        0       #>  2  0.08   254   0.0682   0.0455  #>  3  0.5    254   0.362    0.257   #>  4  1      254   0.616    0.439   #>  5  1.5    254   0.795    0.568   #>  6  2      254   0.922    0.658   #>  7  3      254  17.7     12.7     #>  8  4      254   1.15     0.821   #>  9  6      254   1.21     0.862   #> 10  8      254   1.22     0.872   #> 11  9      254  14.9     10.8     #> 12 12      254   0.366    0.260   #> 13 16      254   0.110    0.0767  #> 14 18      254   9.39     6.92    #> 15 24      254   0.0114   0.00520 #> 16 36      254   0.00500  0       #> 17 37      254   0.165    0.426   #> 18 48      254   0.00500  0  # Example 4: Cross-domain analysis: AEs by age group get_ducklake_table(\"adae\") |>   filter(TRTEMFL == \"Y\") |>   left_join(     get_ducklake_table(\"adsl\") |>       select(USUBJID, AGEGR1, TRT01A),     by = \"USUBJID\"   ) |>   count(AGEGR1, TRT01A.x) |>   arrange(AGEGR1, TRT01A.x) #> # Source:     SQL [?? x 3] #> # Database:   DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpGOHRw4/duckplyr/duckplyr1f1d1af084b4.duckdb] #> # Ordered by: AGEGR1, TRT01A.x #>   AGEGR1 TRT01A.x                 n #>   <chr>  <chr>                <dbl> #> 1 18-64  Placebo                 57 #> 2 18-64  Xanomeline High Dose    86 #> 3 18-64  Xanomeline Low Dose     20 #> 4 >64    Placebo                224 #> 5 >64    Xanomeline High Dose   326 #> 6 >64    Xanomeline Low Dose    407"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"audit-trail-and-compliance","dir":"Articles","previous_headings":"","what":"Audit Trail and Compliance","title":"Clinical Trial Data Lake with ducklake","text":"regulatory submissions, complete audit trail essential:","code":"# Generate audit report for ADSL audit_report <- list_table_snapshots(\"adsl\") audit_report #>    snapshot_id       snapshot_time schema_version #> 16          15 2026-02-06 20:34:34             15 #> 22          21 2026-02-06 20:34:37             21 #> 23          22 2026-02-06 20:34:37             22 #> 24          23 2026-02-06 20:34:37             23 #> 25          24 2026-02-06 20:34:37             24 #> 26          25 2026-02-06 20:34:38             25 #>                                                                                       changes #> 16                                        tables_created, tables_inserted_into, main.adsl, 15 #> 22                    tables_created, tables_dropped, tables_inserted_into, main.adsl, 15, 21 #> 23                    tables_created, tables_dropped, tables_inserted_into, main.adsl, 21, 22 #> 24                    tables_created, tables_dropped, tables_inserted_into, main.adsl, 22, 23 #> 25                    tables_created, tables_dropped, tables_inserted_into, main.adsl, 23, 24 #> 26 tables_created, tables_dropped, tables_inserted_into, main.adsl, main.adae, 16, 24, 25, 26 #>     author              commit_message #> 16 T Gerke         Create ADSL dataset #> 22 T Gerke Add age categorization vars #> 23 T Gerke      Test age categories v1 #> 24 T Gerke    Refine age categories v2 #> 25 T Gerke     Finalize age categories #> 26 T Gerke           Add analysis flag #>                                                                      commit_extra_info #> 16 Derived from DM, SUPPDM, DS, EX; includes treatment dates, safety flags, age groups #> 22                                                                                <NA> #> 23                                                                                <NA> #> 24                                                                                <NA> #> 25                                                                                <NA> #> 26                                                                                <NA>  # Get table metadata from DuckLake system tables adsl_table_meta <- get_metadata_table(\"ducklake_table\") |>   filter(table_name == \"adsl\") |>   collect() adsl_table_meta #> # A tibble: 6 × 8 #>   table_id table_uuid     begin_snapshot end_snapshot schema_id table_name path  #>      <dbl> <chr>                   <dbl>        <dbl>     <dbl> <chr>      <chr> #> 1       15 019c34a9-e235…             15           21         0 adsl       adsl/ #> 2       21 019c34a9-ed2e…             21           22         0 adsl       adsl/ #> 3       22 019c34a9-ee09…             22           23         0 adsl       adsl/ #> 4       23 019c34a9-eebb…             23           24         0 adsl       adsl/ #> 5       24 019c34a9-ef6d…             24           25         0 adsl       adsl/ #> 6       26 019c34a9-f120…             25           NA         0 adsl       adsl/ #> # ℹ 1 more variable: path_is_relative <lgl>  # Export audit information audit_export <- audit_report |>   mutate(     table_name = \"adsl\",     dataset_label = \"Subject-Level Analysis Dataset\"   ) audit_export #>    snapshot_id       snapshot_time schema_version #> 16          15 2026-02-06 20:34:34             15 #> 22          21 2026-02-06 20:34:37             21 #> 23          22 2026-02-06 20:34:37             22 #> 24          23 2026-02-06 20:34:37             23 #> 25          24 2026-02-06 20:34:37             24 #> 26          25 2026-02-06 20:34:38             25 #>                                                                                       changes #> 16                                        tables_created, tables_inserted_into, main.adsl, 15 #> 22                    tables_created, tables_dropped, tables_inserted_into, main.adsl, 15, 21 #> 23                    tables_created, tables_dropped, tables_inserted_into, main.adsl, 21, 22 #> 24                    tables_created, tables_dropped, tables_inserted_into, main.adsl, 22, 23 #> 25                    tables_created, tables_dropped, tables_inserted_into, main.adsl, 23, 24 #> 26 tables_created, tables_dropped, tables_inserted_into, main.adsl, main.adae, 16, 24, 25, 26 #>     author              commit_message #> 16 T Gerke         Create ADSL dataset #> 22 T Gerke Add age categorization vars #> 23 T Gerke      Test age categories v1 #> 24 T Gerke    Refine age categories v2 #> 25 T Gerke     Finalize age categories #> 26 T Gerke           Add analysis flag #>                                                                      commit_extra_info #> 16 Derived from DM, SUPPDM, DS, EX; includes treatment dates, safety flags, age groups #> 22                                                                                <NA> #> 23                                                                                <NA> #> 24                                                                                <NA> #> 25                                                                                <NA> #> 26                                                                                <NA> #>    table_name                  dataset_label #> 16       adsl Subject-Level Analysis Dataset #> 22       adsl Subject-Level Analysis Dataset #> 23       adsl Subject-Level Analysis Dataset #> 24       adsl Subject-Level Analysis Dataset #> 25       adsl Subject-Level Analysis Dataset #> 26       adsl Subject-Level Analysis Dataset"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"cleanup","dir":"Articles","previous_headings":"","what":"Cleanup","title":"Clinical Trial Data Lake with ducklake","text":"’re done, can detach data lake:","code":"detach_ducklake()"},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Clinical Trial Data Lake with ducklake","text":"vignette demonstrated ducklake provides robust infrastructure clinical trial data management: Setup: Created versioned data lake clinical trial data Medallion Architecture: Implemented bronze (raw), silver (cleaned), gold (analysis) layers SDTM Loading: Loaded multiple SDTM domains raw cleaned versions full version control ADaM Derivation: Built analysis datasets (ADSL, ADAE, ADPC) complete data lineage silver gold Regulatory Artifacts: Stored define.xml, ARD, ARM, specifications alongside datasets Organization: Maintained cohesive relationships related datasets documentation Functionality: Demonstrated versioning, time travel, transactions, upserts Analysis: Showed efficient cross-domain queries Compliance: Generated audit trails regulatory requirements raw data preservation using ducklake clinical trial data, ensure: Modern Architecture: Relational database structure inherently relational CDISC data Layered Design: Bronze/silver/gold layers separate raw, cleaned, analysis-ready data Reproducibility: Analyses can exactly recreated; raw data enables reprocessing Traceability: Complete lineage raw source cleaning final analysis Collaboration: Multiple analysts working safely shared data layers Compliance: Regulatory-ready audit trails preserved source data Efficiency: Fast queries across related datasets without loading multiple flat files Data Integrity: Referential integrity checks across related tables Reprocessability: Ability rerun cleaning analysis logic without re-extracting EDC information specific features: vignette(\"ducklake\") - Getting started guide vignette(\"time-travel\") - Time travel version control vignette(\"transactions\") - Transaction management vignette(\"upsert-operations\") - Upsert operations","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/clinical-trial-datalake.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Clinical Trial Data Lake with ducklake","text":"CDISC SDTM CDISC ADaM pharmaverse admiral pharmaversesdtm DuckLake Documentation","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/ducklake.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Started with ducklake","text":"ducklake R package complements existing toolkits duckdb duckplyr packages, supporting new DuckLake ecosystem.","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/ducklake.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting Started with ducklake","text":"Install development version ducklake :","code":"pak::pak(\"tgerke/ducklake-r\")"},{"path":"https://tgerke.github.io/ducklake-r/articles/ducklake.html","id":"create-a-local-duckdb-lakehouse","dir":"Articles","previous_headings":"","what":"Create a local duckdb lakehouse","title":"Getting Started with ducklake","text":"","code":"# install the ducklake extension to duckdb  # requires that you already have DuckDB v1.3.0 or higher install_ducklake()  # create the ducklake attach_ducklake(\"my_ducklake\") # show that we have ducklake files list.files()  # create a table using the Netherlands train traffic dataset  create_table(\"https://blobs.duckdb.org/nl_stations.csv\", \"nl_train_stations\") # show that we now have a .files directory list.files() # main/ is where the parquet files go list.files(\"my_ducklake.ducklake.files/main/nl_train_stations\")  # create a table from an R data.frame create_table(mtcars, \"mtcars_table\") list.files(\"my_ducklake.ducklake.files/main/mtcars_table\")"},{"path":"https://tgerke.github.io/ducklake-r/articles/ducklake.html","id":"view-metadata-and-snapshots","dir":"Articles","previous_headings":"","what":"View metadata and snapshots","title":"Getting Started with ducklake","text":"","code":"# List all tables in the lake get_ducklake_table(\"duckdb_tables\") |>    select(database_name, schema_name, table_name) |>    print(n = Inf)  # View snapshot history get_metadata_table(\"ducklake_snapshot_changes\", ducklake_name = \"my_ducklake\") get_metadata_table(\"ducklake_snapshot\", ducklake_name = \"my_ducklake\")"},{"path":"https://tgerke.github.io/ducklake-r/articles/ducklake.html","id":"cleanup","dir":"Articles","previous_headings":"","what":"Cleanup","title":"Getting Started with ducklake","text":"","code":"# When done, detach from the ducklake detach_ducklake(\"my_ducklake\")"},{"path":"https://tgerke.github.io/ducklake-r/articles/ducklake.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Getting Started with ducklake","text":"Learn modifying tables Explore upsert operations Work transactions Query historical data time travel","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/modifying-tables.html","id":"two-approaches-for-table-modifications","dir":"Articles","previous_headings":"","what":"Two approaches for table modifications","title":"Modifying Tables","text":"ducklake provides two complementary approaches modifying tables, following tidyverse conventions:","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/modifying-tables.html","id":"data-frame-approach-rows_-functions","dir":"Articles","previous_headings":"Two approaches for table modifications","what":"1. data.frame approach (rows_* functions)","title":"Modifying Tables","text":"Best data R (data.frames/tibbles) want apply table: Pros: Explicit, familiar dplyr syntax, in_place = TRUE default DuckLakeUse : data.frames/tibbles ready apply","code":"# Prepare your data in R updates <- data.frame(id = c(1, 2), value = c(\"new1\", \"new2\"))  # Apply to table rows_update(get_ducklake_table(\"my_table\"), updates, by = \"id\")  # Update existing rows rows_insert(get_ducklake_table(\"my_table\"), new_data, by = \"id\")  # Insert new rows rows_upsert(get_ducklake_table(\"my_table\"), updates, by = \"id\")  # Update existing or insert new rows_delete(get_ducklake_table(\"my_table\"), to_delete, by = \"id\")  # Delete rows by key"},{"path":"https://tgerke.github.io/ducklake-r/articles/modifying-tables.html","id":"pipeline-approach-_table-functions","dir":"Articles","previous_headings":"Two approaches for table modifications","what":"2. Pipeline approach (*_table functions)","title":"Modifying Tables","text":"Best ’re transforming data dplyr want apply results table: Pros: Chainable, works pipelines, table name inferenceUse : Transforming data filter(), mutate(), summarize(), etc.","code":"# Build transformation pipeline, then execute get_ducklake_table(\"my_table\") |>   filter(status == \"active\") |>   mutate(processed = TRUE) |>   ducklake_exec()  # for updates  source_table |>   select(id, value) |>   mutate(value = toupper(value)) |>   upsert_table(\"target_table\", by = \"id\")  # for merge/upsert"},{"path":[]},{"path":"https://tgerke.github.io/ducklake-r/articles/modifying-tables.html","id":"update-with-rows_update","dir":"Articles","previous_headings":"Examples","what":"Update with rows_update()","title":"Modifying Tables","text":"","code":"# update the first row with ducklake::rows_update() # copy = TRUE and in_place = TRUE are the defaults for DuckLake operations rows_update(   get_ducklake_table(\"nl_train_stations\"),   data.frame(     uic = 8400319,     name_short = \"NEW\"   ),   by = \"uic\",   copy = TRUE,   unmatched = \"ignore\" )  # View the change get_ducklake_table(\"nl_train_stations\") |>   filter(uic == 8400319) |>   select(uic, name_short)"},{"path":"https://tgerke.github.io/ducklake-r/articles/modifying-tables.html","id":"update-with-pipeline-and-ducklake_exec","dir":"Articles","previous_headings":"Examples","what":"Update with pipeline and ducklake_exec()","title":"Modifying Tables","text":"","code":"# update with mutate and ducklake::ducklake_exec # table name is automatically inferred from the pipeline get_ducklake_table(\"nl_train_stations\") |>   mutate(     name_long = dplyr::case_when(       code == \"ASB\" ~ \"Johan Cruijff ArenA\",       .default = name_long     )   ) |>   ducklake_exec()"},{"path":"https://tgerke.github.io/ducklake-r/articles/modifying-tables.html","id":"preview-sql-before-execution","dir":"Articles","previous_headings":"Examples","what":"Preview SQL before execution","title":"Modifying Tables","text":"","code":"# if we want, we can always view the sql that will be submitted in advance get_ducklake_table(\"nl_train_stations\") |>   mutate(     name_long = dplyr::case_when(       code == \"ASB\" ~ \"Johan Cruijff ArenA\",       .default = name_long     )   ) |>   show_ducklake_query()"},{"path":"https://tgerke.github.io/ducklake-r/articles/modifying-tables.html","id":"filter-and-execute","dir":"Articles","previous_headings":"Examples","what":"Filter and execute","title":"Modifying Tables","text":"","code":"# filter using ducklake::ducklake_exec # with .quiet=FALSE we can see sql on execution, including the original dplyr get_ducklake_table(\"nl_train_stations\") |>   filter(uic == 8400319 | code == \"ASB\") |>   ducklake_exec(.quiet = FALSE)  # show our current table get_ducklake_table(\"nl_train_stations\")"},{"path":"https://tgerke.github.io/ducklake-r/articles/time-travel.html","id":"introduction-to-time-travel","dir":"Articles","previous_headings":"","what":"Introduction to time travel","title":"Time Travel Queries","text":"DuckLake supports querying historical data specific points time using built-snapshot functionality. allows : View data existed specific timestamp Query specific versions tables Restore tables previous states Audit changes time","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/time-travel.html","id":"time-travel-functions","dir":"Articles","previous_headings":"","what":"Time travel functions","title":"Time Travel Queries","text":"package provides several time-travel functions:","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/time-travel.html","id":"query-data-at-a-specific-timestamp","dir":"Articles","previous_headings":"Time travel functions","what":"Query data at a specific timestamp","title":"Time Travel Queries","text":"","code":"# Query data as it existed at a specific timestamp get_ducklake_table_asof(\"my_delta_table\", \"2024-01-15 10:30:00\") |>   filter(status == \"active\") |>   collect()  # Query data as it existed yesterday yesterday <- Sys.time() - (24 * 60 * 60) get_ducklake_table_asof(\"my_delta_table\", yesterday) |>   summarise(n = n())"},{"path":"https://tgerke.github.io/ducklake-r/articles/time-travel.html","id":"query-a-specific-version","dir":"Articles","previous_headings":"Time travel functions","what":"Query a specific version","title":"Time Travel Queries","text":"","code":"# Query a specific version/snapshot number get_ducklake_table_version(\"my_delta_table\", version = 5) |>   collect()"},{"path":"https://tgerke.github.io/ducklake-r/articles/time-travel.html","id":"list-available-snapshots","dir":"Articles","previous_headings":"Time travel functions","what":"List available snapshots","title":"Time Travel Queries","text":"","code":"# List all available snapshots for a table list_table_snapshots(\"my_delta_table\")"},{"path":"https://tgerke.github.io/ducklake-r/articles/time-travel.html","id":"restore-to-a-previous-version","dir":"Articles","previous_headings":"Time travel functions","what":"Restore to a previous version","title":"Time Travel Queries","text":"","code":"# Restore table to a previous version by version number restore_table_version(\"my_delta_table\", version = 3)  # Or restore to a specific timestamp restore_table_version(\"my_delta_table\", timestamp = \"2024-01-15 10:00:00\")"},{"path":"https://tgerke.github.io/ducklake-r/articles/time-travel.html","id":"use-cases","dir":"Articles","previous_headings":"","what":"Use cases","title":"Time Travel Queries","text":"Time travel particularly useful : Auditing: Track changed Debugging: Identify data issues introduced Recovery: Restore accidentally modified deleted data Reporting: Generate reports based historical data snapshots Compliance: Maintain historical records regulatory requirements","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/time-travel.html","id":"example-workflow","dir":"Articles","previous_headings":"","what":"Example workflow","title":"Time Travel Queries","text":"","code":"# Setup install_ducklake() attach_ducklake(\"my_ducklake\") create_table(employee_data, \"employees\")  # Make some changes over time rows_update(get_ducklake_table(\"employees\"), updates_jan, by = \"id\") rows_update(get_ducklake_table(\"employees\"), updates_feb, by = \"id\")  # View snapshot history list_table_snapshots(\"employees\")  # Compare current data with previous version current <- get_ducklake_table(\"employees\") |> collect() previous <- get_ducklake_table_version(\"employees\", version = 2) |> collect()  # If needed, restore to previous version restore_table_version(\"employees\", version = 2)"},{"path":"https://tgerke.github.io/ducklake-r/articles/transactions.html","id":"transaction-support","dir":"Articles","previous_headings":"","what":"Transaction support","title":"Working with Transactions","text":"Group multiple operations together ACID transactions. ensures either operations succeed none , maintaining data consistency.","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/transactions.html","id":"basic-transaction-workflow","dir":"Articles","previous_headings":"","what":"Basic transaction workflow","title":"Working with Transactions","text":"","code":"# Check what data we currently have get_ducklake_table(\"nl_train_stations\") |>   filter(code %in% c(\"HT\", \"ASB\")) |>   select(code, name_short) |>   collect() # Start a transaction begin_transaction()  # Make multiple changes atomically within the transaction duckplyr::db_exec(\"UPDATE nl_train_stations SET name_short = 'COMMITTED_CHANGE' WHERE code = 'HT'\") duckplyr::db_exec(\"UPDATE nl_train_stations SET name_short = 'ALSO_COMMITTED' WHERE code = 'ASB'\")  # Commit both changes together commit_transaction()  # Add author and commit message metadata to the snapshot set_snapshot_metadata(   ducklake_name = \"my_ducklake\",   author = \"Data Team\",   commit_message = \"Updated station names for clarity\" )  # Verify the changes were applied get_ducklake_table(\"nl_train_stations\") |>   filter(code %in% c(\"HT\", \"ASB\")) |>   select(code, name_short) |>   collect()"},{"path":"https://tgerke.github.io/ducklake-r/articles/transactions.html","id":"view-commit-history","dir":"Articles","previous_headings":"","what":"View commit history","title":"Working with Transactions","text":"","code":"# View the recent commit history with metadata get_metadata_table(\"ducklake_snapshot_changes\", ducklake_name = \"my_ducklake\") |>   select(snapshot_id, changes_made, author, commit_message) |>   collect() |>   tail(3)"},{"path":"https://tgerke.github.io/ducklake-r/articles/transactions.html","id":"rolling-back-transactions","dir":"Articles","previous_headings":"","what":"Rolling back transactions","title":"Working with Transactions","text":"need undo changes committing:","code":"# Start another transaction begin_transaction()  # Make a change we'll roll back duckplyr::db_exec(\"UPDATE nl_train_stations SET name_short = 'ROLLBACK_TEST' WHERE code = 'HT'\")  # Decide to rollback instead of commit rollback_transaction()  # Verify the change was NOT applied (should still be \"COMMITTED_CHANGE\") get_ducklake_table(\"nl_train_stations\") |>   filter(code == \"HT\") |>   select(code, name_short) |>   collect()"},{"path":"https://tgerke.github.io/ducklake-r/articles/transactions.html","id":"key-concepts","dir":"Articles","previous_headings":"","what":"Key concepts","title":"Working with Transactions","text":"begin_transaction(): Start new transaction commit_transaction(): Apply changes made within transaction rollback_transaction(): Discard changes made within transaction set_snapshot_metadata(): Add metadata (author, commit message) snapshots Transactions essential maintaining data integrity making multiple related changes.","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/upsert-operations.html","id":"what-is-upsert","dir":"Articles","previous_headings":"","what":"What is upsert?","title":"Upsert Operations","text":"Upsert (merge) operations allow update existing rows insert new ones based key. useful data may contain updates existing records new records.","code":""},{"path":"https://tgerke.github.io/ducklake-r/articles/upsert-operations.html","id":"using-rows_upsert-with-data-frames","dir":"Articles","previous_headings":"","what":"Using rows_upsert() with data.frames","title":"Upsert Operations","text":"data R want upsert table:","code":"# Create some data to upsert upsert_data <- data.frame(   uic = c(8400319, 9999999),  # 8400319 exists, 9999999 is new   name_short = c(\"UPDATED\", \"NEW\"),   name_long = c(\"Updated Station\", \"New Station\"),   code = c(\"UPD\", \"NEW\"),   stringsAsFactors = FALSE )  # Use rows_upsert for data.frames (copy = TRUE and in_place = TRUE by default) rows_upsert(   get_ducklake_table(\"nl_train_stations\"),   upsert_data,   by = \"uic\",   copy = TRUE )  # View the results - both the updated and new row get_ducklake_table(\"nl_train_stations\") |>   filter(uic %in% c(8400319, 9999999)) |>   select(uic, name_short, name_long, code)"},{"path":"https://tgerke.github.io/ducklake-r/articles/upsert-operations.html","id":"using-upsert_table-with-pipelines","dir":"Articles","previous_headings":"","what":"Using upsert_table() with pipelines","title":"Upsert Operations","text":"’re transforming data dplyr want upsert results:","code":"# Create a source table source_data <- data.frame(   id = c(1, 2, 3),   value = c(\"apple\", \"banana\", \"cherry\"),   count = c(10, 20, 30) ) create_table(source_data, \"source_table\")  # Create a target table with some overlapping data target_data <- data.frame(   id = c(1, 2),   value = c(\"old_apple\", \"old_banana\"),   count = c(5, 15) ) create_table(target_data, \"target_table\")  # Transform and upsert in a pipeline get_ducklake_table(\"source_table\") |>   select(id, value, count) |>   mutate(value = toupper(value)) |>   upsert_table(\"target_table\", by = \"id\")  # View the merged results get_ducklake_table(\"target_table\") |>   select(id, value, count)"},{"path":"https://tgerke.github.io/ducklake-r/articles/upsert-operations.html","id":"key-considerations","dir":"Articles","previous_headings":"","what":"Key considerations","title":"Upsert Operations","text":"parameter specifies column(s) use key matching rows_upsert(), copy = TRUE in_place = TRUE defaults DuckLake operations Existing rows updated, new rows inserted based key match","code":""},{"path":"https://tgerke.github.io/ducklake-r/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Travis Gerke. Author, maintainer.","code":""},{"path":"https://tgerke.github.io/ducklake-r/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Gerke T (2026). ducklake: Interact DuckLake R. R package version 0.0.0.9000, https://tgerke.github.io/ducklake-r/.","code":"@Manual{,   title = {ducklake: Interact with DuckLake from R},   author = {Travis Gerke},   year = {2026},   note = {R package version 0.0.0.9000},   url = {https://tgerke.github.io/ducklake-r/}, }"},{"path":"https://tgerke.github.io/ducklake-r/index.html","id":"ducklake-","dir":"","previous_headings":"","what":"ducklake: Interact with DuckLake from R","title":"ducklake: Interact with DuckLake from R","text":"ducklake R package brings versioned data lake infrastructure data-intensive workflows. Built DuckDB DuckLake, provides ACID transactions, automatic versioning, time travel queries, complete audit trails.","code":""},{"path":"https://tgerke.github.io/ducklake-r/index.html","id":"why-ducklake","dir":"","previous_headings":"","what":"Why DuckLake?","title":"ducklake: Interact with DuckLake from R","text":"Many industries rely flat-file workflows (CSV, XPT, Excel, etc.) create significant data management challenges: Disconnected flat files: Related datasets stored separate files despite inherently relational Lost audit trails: automatic tracking changed Version control gaps: Multiple dataset versions scattered across folders unclear provenance Reproducibility issues: Inability recreate analyses specific time points Collaboration friction: Multiple analysts working different versions data Compliance challenges: Difficulty demonstrating data integrity audit trails regulated industries DuckLake solves problems implementing versioned data lake architecture : Preserves relational structure related datasets Automatically versions every data change timestamps metadata Enables time travel recreate analyses exactly run Provides complete audit trails author attribution commit messages Supports layered architecture (bronze/silver/gold) data lineage raw analysis-ready Allows multiple team members collaborate safely shared data","code":""},{"path":"https://tgerke.github.io/ducklake-r/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"ducklake: Interact with DuckLake from R","text":"Install development version ducklake :","code":"pak::pak(\"tgerke/ducklake-r\")"},{"path":"https://tgerke.github.io/ducklake-r/index.html","id":"quick-example-layered-data-workflow","dir":"","previous_headings":"","what":"Quick example: Layered data workflow","title":"ducklake: Interact with DuckLake from R","text":"","code":"library(ducklake) library(dplyr)  # Install the ducklake extension (requires DuckDB v1.3.0 or higher) install_ducklake()  # Create a data lake in a temporary directory attach_ducklake(\"my_data_lake\", lake_path = tempdir())  # Bronze layer: Load raw data exactly as received with_transaction(   create_table(mtcars, \"vehicles_raw\"),   author = \"Data Engineer\",   commit_message = \"Initial load of raw vehicle data\" )  # Silver layer: Apply cleaning transformations with_transaction(   get_ducklake_table(\"vehicles_raw\") |>     mutate(cyl = as.character(cyl)) |>     create_table(\"vehicles_clean\"),   author = \"Data Engineer\",    commit_message = \"Clean and standardize vehicle data\" )  # Gold layer: Create analysis dataset with business logic with_transaction(   get_ducklake_table(\"vehicles_clean\") |>     mutate(       efficiency = case_when(         mpg < 15 ~ \"Low\",         mpg < 25 ~ \"Medium\",         TRUE ~ \"High\"       )     ) |>     create_table(\"vehicles_analysis\"),   author = \"Data Analyst\",   commit_message = \"Create analysis-ready dataset with efficiency categories\" )  # Update the silver layer with additional transformations with_transaction(   get_ducklake_table(\"vehicles_clean\") |>     mutate(gear = as.integer(gear)) |>     replace_table(\"vehicles_clean\"),   author = \"Data Engineer\",   commit_message = \"Add gear type conversion to silver layer\" )  # View the analysis dataset get_ducklake_table(\"vehicles_analysis\") |>   select(mpg, cyl, efficiency) |>   head(3) #> # Source:   SQL [?? x 3] #> # Database: DuckDB 1.4.4 [tgerke@Darwin 23.6.0:R 4.5.2//private/var/folders/b7/664jmq55319dcb7y4jdb39zr0000gq/T/RtmpOWJ6ih/duckplyr/duckplyr111960e4a3f1.duckdb] #>     mpg cyl   efficiency #>   <dbl> <chr> <chr>      #> 1  21   6.0   Medium     #> 2  21   6.0   Medium     #> 3  22.8 4.0   Medium  # View complete audit trail across all layers with author and commit messages list_table_snapshots() #>   snapshot_id       snapshot_time schema_version #> 1           0 2026-02-06 20:31:26              0 #> 2           1 2026-02-06 20:31:26              1 #> 3           2 2026-02-06 20:31:26              2 #> 4           3 2026-02-06 20:31:26              3 #> 5           4 2026-02-06 20:31:26              4 #>                                                                           changes #> 1                                                           schemas_created, main #> 2                      tables_created, tables_inserted_into, main.vehicles_raw, 1 #> 3                    tables_created, tables_inserted_into, main.vehicles_clean, 2 #> 4                 tables_created, tables_inserted_into, main.vehicles_analysis, 3 #> 5 tables_created, tables_dropped, tables_inserted_into, main.vehicles_clean, 2, 4 #>          author                                           commit_message #> 1          <NA>                                                     <NA> #> 2 Data Engineer                         Initial load of raw vehicle data #> 3 Data Engineer                       Clean and standardize vehicle data #> 4  Data Analyst Create analysis-ready dataset with efficiency categories #> 5 Data Engineer                 Add gear type conversion to silver layer #>   commit_extra_info #> 1              <NA> #> 2              <NA> #> 3              <NA> #> 4              <NA> #> 5              <NA>  # Time travel: Query the silver layer as it existed at snapshot 2 (before updates) get_ducklake_table_version(\"vehicles_clean\", version = 2) |>   select(mpg, cyl, gear) |>   head(3) #> # Source:   SQL [?? x 3] #> # Database: DuckDB 1.4.4 [tgerke@Darwin 23.6.0:R 4.5.2//private/var/folders/b7/664jmq55319dcb7y4jdb39zr0000gq/T/RtmpOWJ6ih/duckplyr/duckplyr111960e4a3f1.duckdb] #>     mpg cyl    gear #>   <dbl> <chr> <dbl> #> 1  21   6.0       4 #> 2  21   6.0       4 #> 3  22.8 4.0       4  # Clean up detach_ducklake(\"my_data_lake\")"},{"path":"https://tgerke.github.io/ducklake-r/index.html","id":"medallion-architecture","dir":"","previous_headings":"","what":"Medallion architecture","title":"ducklake: Interact with DuckLake from R","text":"ducklake implements layered data architecture (medallion pattern) ensures data quality traceability: Bronze layer (raw): Data exactly received source systems—preserves original data audit trails Silver layer (cleaned): Standardized, cleaned data transformations validations—trusted source analysis Gold layer (analytics): Business-logic datasets optimized specific analyses, dashboards, reports layer automatically versioned, providing complete data lineage raw source analysis-ready datasets. approach enables: Complete audit trail: Original data preserved alongside transformations Reprocessability: Reprocess bronze cleaning logic changes without re-extracting source Data lineage: Clear progression raw → cleaned → analysis-ready Validation: Compare layers verify transformations Quality assurance: Separate concerns ingestion, cleaning, analysis","code":""},{"path":"https://tgerke.github.io/ducklake-r/index.html","id":"learn-more","dir":"","previous_headings":"","what":"Learn more","title":"ducklake: Interact with DuckLake from R","text":"Check pkgdown site detailed vignettes: Clinical Trial Data Lake - Start : Complete workflow SDTM ADaM regulatory artifacts Getting Started - Basic lakehouse operations Modifying Tables - Two approaches table modifications Upsert Operations - Merge update data Transactions - ACID transaction support Time Travel - Query historical data","code":""},{"path":"https://tgerke.github.io/ducklake-r/index.html","id":"key-features","dir":"","previous_headings":"","what":"Key features","title":"ducklake: Interact with DuckLake from R","text":"Versioned data lake: Every data change automatically tracked timestamps metadata Lightweight snapshots: Create unlimited snapshots without frequent compacting steps Medallion architecture: Bronze/silver/gold layers data lineage quality ACID transactions: Atomic updates concurrent access transactional guarantees multi-table operations Time travel: Query data exactly existed point time—essential reproducibility Performance-oriented: Uses Parquet columnar storage statistics filter pushdown, enabling fast queries large datasets Schema evolution: Adapt table schemas time requirements change Tidyverse interface: Familiar dplyr syntax data manipulation Two complementary approaches: rows_* functions data.frames pipeline functions dplyr workflows Complete audit trails: changed , , —suitable regulated industries Seamless integration: Works duckdb, duckplyr, broader R ecosystem","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/attach_ducklake.html","id":null,"dir":"Reference","previous_headings":"","what":"Create or attach a ducklake — attach_ducklake","title":"Create or attach a ducklake — attach_ducklake","text":"function wrapper ducklake ATTACH command. create new DuckDB-backed DuckLake specified name exist, connect existing DuckLake exist. connection stored package environment can closed detach_ducklake().","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/attach_ducklake.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create or attach a ducklake — attach_ducklake","text":"","code":"attach_ducklake(ducklake_name, lake_path = NULL)"},{"path":"https://tgerke.github.io/ducklake-r/reference/attach_ducklake.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create or attach a ducklake — attach_ducklake","text":"ducklake_name Name ducklake file, ducklake:{ducklake_name}.ducklake lake_path Optional directory path ducklake. specified, ducklake database file Parquet data files stored location. specified, ducklake created current working directory data files {ducklake_name}.ducklake.files.","code":""},{"path":[]},{"path":"https://tgerke.github.io/ducklake-r/reference/begin_transaction.html","id":null,"dir":"Reference","previous_headings":"","what":"Begin a transaction — begin_transaction","title":"Begin a transaction — begin_transaction","text":"Starts new transaction DuckDB connection. subsequent operations part transaction committed rolled back.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/begin_transaction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Begin a transaction — begin_transaction","text":"","code":"begin_transaction(conn = NULL)"},{"path":"https://tgerke.github.io/ducklake-r/reference/begin_transaction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Begin a transaction — begin_transaction","text":"conn Optional DuckDB connection object. provided, uses default ducklake connection.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/begin_transaction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Begin a transaction — begin_transaction","text":"Invisibly returns TRUE success","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/begin_transaction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Begin a transaction — begin_transaction","text":"Transactions allow group multiple operations together ensure either succeed fail. Use commit_transaction() apply changes rollback_transaction() discard . DuckDB supports full ACID transactions multiple isolation levels.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/begin_transaction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Begin a transaction — begin_transaction","text":"","code":"if (FALSE) { # \\dontrun{ # Start a transaction begin_transaction()  # Make some changes get_ducklake_table(\"my_table\") |>   filter(status == \"pending\") |>   mutate(status = \"processed\") |>   ducklake_exec()  # Commit if everything looks good commit_transaction()  # Or rollback if something went wrong # rollback_transaction() } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/commit_transaction.html","id":null,"dir":"Reference","previous_headings":"","what":"Commit a transaction — commit_transaction","title":"Commit a transaction — commit_transaction","text":"Commits current transaction, making changes permanent. Optionally adds metadata (author, commit message, extra info) snapshot.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/commit_transaction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Commit a transaction — commit_transaction","text":"","code":"commit_transaction(   conn = NULL,   author = NULL,   commit_message = NULL,   commit_extra_info = NULL )"},{"path":"https://tgerke.github.io/ducklake-r/reference/commit_transaction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Commit a transaction — commit_transaction","text":"conn Optional DuckDB connection object. provided, uses default ducklake connection. author Optional author name associate snapshot commit_message Optional commit message describing changes commit_extra_info Optional extra information commit","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/commit_transaction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Commit a transaction — commit_transaction","text":"Invisibly returns TRUE success","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/commit_transaction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Commit a transaction — commit_transaction","text":"function commits changes made since begin_transaction() called, making permanent database. DuckLake automatically tracks changes ducklake_snapshot_changes metadata table. author, commit_message, commit_extra_info provided, automatically added snapshot metadata committing.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/commit_transaction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Commit a transaction — commit_transaction","text":"","code":"if (FALSE) { # \\dontrun{ # Basic commit begin_transaction() # ... make changes ... commit_transaction()  # Commit with metadata begin_transaction() create_table(mtcars, \"cars\") commit_transaction(   author = \"John Doe\",   commit_message = \"Add cars dataset\" ) } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/create_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a DuckLake table — create_table","title":"Create a DuckLake table — create_table","text":"Create DuckLake table","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/create_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a DuckLake table — create_table","text":"","code":"create_table(data_source, table_name)"},{"path":"https://tgerke.github.io/ducklake-r/reference/create_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a DuckLake table — create_table","text":"data_source Raw data source. Can : URL (http:// https://) file path (e.g., \"data.csv\", \"data.parquet\") R data.frame tibble lazy table (tbl_duckdb_connection tbl_lazy) table_name Name new table","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/create_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a DuckLake table — create_table","text":"","code":"if (FALSE) { # \\dontrun{ # From URL create_table(\"https://example.com/data.csv\", \"my_table\")  # From local file create_table(\"data.csv\", \"my_table\")  # From data.frame create_table(mtcars, \"my_table\")  # From lazy table (pipe-friendly) get_ducklake_table(\"source_table\") %>%    filter(x > 5) %>%   create_table(\"filtered_table\") } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/detach_ducklake.html","id":null,"dir":"Reference","previous_headings":"","what":"Detach from a ducklake — detach_ducklake","title":"Detach from a ducklake — detach_ducklake","text":"Closes DuckDB connection detaches current DuckLake.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/detach_ducklake.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detach from a ducklake — detach_ducklake","text":"","code":"detach_ducklake(ducklake_name = NULL)"},{"path":"https://tgerke.github.io/ducklake-r/reference/detach_ducklake.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detach from a ducklake — detach_ducklake","text":"ducklake_name Optional name ducklake detach. provided, closes current connection.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/detach_ducklake.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detach from a ducklake — detach_ducklake","text":"","code":"if (FALSE) { # \\dontrun{ attach_ducklake(\"my_ducklake\") # ... do work ... detach_ducklake(\"my_ducklake\") } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/ducklake_exec.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute DuckLake operations from dplyr queries — ducklake_exec","title":"Execute DuckLake operations from dplyr queries — ducklake_exec","text":"Execute DuckLake operations dplyr queries","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/ducklake_exec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute DuckLake operations from dplyr queries — ducklake_exec","text":"","code":"ducklake_exec(.data, table_name = NULL, .quiet = TRUE)"},{"path":"https://tgerke.github.io/ducklake-r/reference/ducklake_exec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute DuckLake operations from dplyr queries — ducklake_exec","text":".data dplyr query object (tbl_lazy) accumulated operations table_name target table name operation. provided, extracted table attribute (set get_ducklake_table()) .quiet Logical, whether suppress debug output (default TRUE)","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/ducklake_exec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Execute DuckLake operations from dplyr queries — ducklake_exec","text":"result duckplyr::db_exec()","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/ducklake_exec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Execute DuckLake operations from dplyr queries — ducklake_exec","text":"function automatically detects type operation based dplyr verbs: Filter-queries generate DELETE operations (removes rows match filter) Queries mutate() generate UPDATE operations queries generate INSERT operations","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/ducklake_exec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Execute DuckLake operations from dplyr queries — ducklake_exec","text":"","code":"if (FALSE) { # \\dontrun{ # Delete rows that don't match filter (table name inferred) get_ducklake_table(\"my_table\") |>   filter(status == \"inactive\") |>   ducklake_exec()  # Update specific rows (table name inferred) get_ducklake_table(\"my_table\") |>   filter(id == 123) |>   mutate(status = \"updated\") |>   ducklake_exec()  # Or provide table name explicitly tbl(con, \"my_table\") |>   select(id, name) |>   mutate(computed_field = name * 2) |>   ducklake_exec(\"my_table\") } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/extract_assignments_from_sql.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract column assignments from SQL SELECT statement — extract_assignments_from_sql","title":"Extract column assignments from SQL SELECT statement — extract_assignments_from_sql","text":"Extract column assignments SQL SELECT statement","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/extract_assignments_from_sql.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract column assignments from SQL SELECT statement — extract_assignments_from_sql","text":"","code":"extract_assignments_from_sql(sql_text)"},{"path":"https://tgerke.github.io/ducklake-r/reference/extract_assignments_from_sql.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract column assignments from SQL SELECT statement — extract_assignments_from_sql","text":"sql_text SQL SELECT statement","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/extract_assignments_from_sql.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract column assignments from SQL SELECT statement — extract_assignments_from_sql","text":"string comma-separated column assignments UPDATE SET clause","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_connection.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the current DuckLake connection — get_ducklake_connection","title":"Get the current DuckLake connection — get_ducklake_connection","text":"function retrieves active DuckLake connection. connection explicitly set via set_ducklake_connection(), falls back duckplyr's default DuckDB connection seamless integration.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_connection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the current DuckLake connection — get_ducklake_connection","text":"","code":"get_ducklake_connection()"},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_connection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the current DuckLake connection — get_ducklake_connection","text":"DuckDB connection object","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_connection.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Get the current DuckLake connection — get_ducklake_connection","text":"function uses duckplyr:::get_default_duckdb_connection() fallback. unexported function duckplyr, necessary proper integration duckplyr ecosystem explicit ducklake connection set.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a DuckLake table — get_ducklake_table","title":"Get a DuckLake table — get_ducklake_table","text":"Get DuckLake table","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a DuckLake table — get_ducklake_table","text":"","code":"get_ducklake_table(tbl_name)"},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a DuckLake table — get_ducklake_table","text":"tbl_name Character string, name table retrieve","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a DuckLake table — get_ducklake_table","text":"DuckLake table class tbl_duckdb_connection table name stored attribute","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table_asof.html","id":null,"dir":"Reference","previous_headings":"","what":"Query a table at a specific timestamp (time travel) — get_ducklake_table_asof","title":"Query a table at a specific timestamp (time travel) — get_ducklake_table_asof","text":"Retrieves data DuckLake table existed specific point time using DuckLake's (TIMESTAMP => ...) syntax.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table_asof.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query a table at a specific timestamp (time travel) — get_ducklake_table_asof","text":"","code":"get_ducklake_table_asof(table_name, timestamp, conn = NULL)"},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table_asof.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query a table at a specific timestamp (time travel) — get_ducklake_table_asof","text":"table_name name table query timestamp POSIXct timestamp character string ISO 8601 format (e.g., \"2024-01-15 10:30:00\") conn Optional DuckDB connection object. provided, uses default ducklake connection.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table_asof.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query a table at a specific timestamp (time travel) — get_ducklake_table_asof","text":"dplyr lazy query object (tbl_lazy) can manipulated dplyr verbs","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table_asof.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Query a table at a specific timestamp (time travel) — get_ducklake_table_asof","text":"DuckLake supports time-travel queries, allowing query historical data existed specific timestamp. uses syntax: SELECT * table (TIMESTAMP => 'timestamp') useful : Auditing changes time Recovering accidentally deleted modified data Comparing data states across different time points Regulatory compliance data lineage documentation timestamp must within range available snapshots table. Use list_table_snapshots() see available snapshot times.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table_asof.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query a table at a specific timestamp (time travel) — get_ducklake_table_asof","text":"","code":"if (FALSE) { # \\dontrun{ # Query data as it existed yesterday yesterday <- Sys.time() - (24 * 60 * 60) get_ducklake_table_asof(\"my_table\", yesterday) |>   filter(category == \"A\") |>   collect()  # Query data at a specific snapshot time snapshots <- list_table_snapshots(\"my_table\") get_ducklake_table_asof(\"my_table\", snapshots$snapshot_time[2]) |>   summarise(total = sum(amount)) } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Query a table at a specific version/snapshot — get_ducklake_table_version","title":"Query a table at a specific version/snapshot — get_ducklake_table_version","text":"Retrieves data DuckLake table specific snapshot ID using DuckLake's (VERSION => ...) syntax.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query a table at a specific version/snapshot — get_ducklake_table_version","text":"","code":"get_ducklake_table_version(table_name, version, conn = NULL)"},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table_version.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query a table at a specific version/snapshot — get_ducklake_table_version","text":"table_name name table query version snapshot_id query (get list_table_snapshots()) conn Optional DuckDB connection object. provided, uses default ducklake connection.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query a table at a specific version/snapshot — get_ducklake_table_version","text":"dplyr lazy query object (tbl_lazy) can manipulated dplyr verbs","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table_version.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Query a table at a specific version/snapshot — get_ducklake_table_version","text":"function allows query specific snapshot table using snapshot_id. uses syntax: SELECT * table (VERSION => snapshot_id) time create modify table within transaction, DuckLake creates new snapshot unique snapshot_id. Note snapshot_id schema_version typically value - represent snapshot identifier. Use list_table_snapshots(table_name) see available snapshots IDs.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_ducklake_table_version.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query a table at a specific version/snapshot — get_ducklake_table_version","text":"","code":"if (FALSE) { # \\dontrun{ # Get available snapshots snapshots <- list_table_snapshots(\"my_table\")  # Query the first snapshot version get_ducklake_table_version(\"my_table\", snapshots$snapshot_id[1]) |>   filter(status == \"active\") |>   collect() } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/get_metadata_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a DuckLake metadata table — get_metadata_table","title":"Get a DuckLake metadata table — get_metadata_table","text":"Get DuckLake metadata table","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_metadata_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a DuckLake metadata table — get_metadata_table","text":"","code":"get_metadata_table(tbl_name, ducklake_name = NULL)"},{"path":"https://tgerke.github.io/ducklake-r/reference/get_metadata_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a DuckLake metadata table — get_metadata_table","text":"tbl_name Character string, name table retrieve ducklake_name Character string, name ducklake database (optional, defaults current active ducklake)","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/get_metadata_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a DuckLake metadata table — get_metadata_table","text":"DuckLake table class tbl_duckdb_connection","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/install_ducklake.html","id":null,"dir":"Reference","previous_headings":"","what":"Install the ducklake extension to duckdb — install_ducklake","title":"Install the ducklake extension to duckdb — install_ducklake","text":"needs run system.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/install_ducklake.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install the ducklake extension to duckdb — install_ducklake","text":"","code":"install_ducklake()"},{"path":"https://tgerke.github.io/ducklake-r/reference/install_ducklake.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Install the ducklake extension to duckdb — install_ducklake","text":"","code":"ducklake::install_ducklake()"},{"path":"https://tgerke.github.io/ducklake-r/reference/list_table_snapshots.html","id":null,"dir":"Reference","previous_headings":"","what":"List available snapshots for a table — list_table_snapshots","title":"List available snapshots for a table — list_table_snapshots","text":"Retrieves information available snapshots/versions table.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/list_table_snapshots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List available snapshots for a table — list_table_snapshots","text":"","code":"list_table_snapshots(table_name = NULL, ducklake_name = NULL, conn = NULL)"},{"path":"https://tgerke.github.io/ducklake-r/reference/list_table_snapshots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List available snapshots for a table — list_table_snapshots","text":"table_name name table query ducklake_name name ducklake (database) query. NULL, attempt infer current database. conn Optional DuckDB connection object. provided, uses default ducklake connection.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/list_table_snapshots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List available snapshots for a table — list_table_snapshots","text":"data frame snapshot information (version, timestamp, etc.)","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/list_table_snapshots.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List available snapshots for a table — list_table_snapshots","text":"function queries snapshot history table, showing available versions timestamps. useful understanding historical versions available time-travel queries. Note: exact format availability information depends table format (Delta Lake, Iceberg, etc.).","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/list_table_snapshots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List available snapshots for a table — list_table_snapshots","text":"","code":"if (FALSE) { # \\dontrun{ # List all snapshots for a table list_table_snapshots(\"my_table\") } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/replace_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace a table with modified data and create a new snapshot — replace_table","title":"Replace a table with modified data and create a new snapshot — replace_table","text":"Replace table modified data create new snapshot","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/replace_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace a table with modified data and create a new snapshot — replace_table","text":"","code":"replace_table(.data, table_name, .quiet = TRUE)"},{"path":"https://tgerke.github.io/ducklake-r/reference/replace_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace a table with modified data and create a new snapshot — replace_table","text":".data dplyr query object (tbl_lazy) transformations table_name Table name replace .quiet Logical, whether suppress messages (default TRUE)","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/replace_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace a table with modified data and create a new snapshot — replace_table","text":"Invisibly returns NULL","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/replace_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Replace a table with modified data and create a new snapshot — replace_table","text":"function designed schema changes bulk transformations create new versioned snapshot. : Collects transformed data Drops existing table Creates new table updated schema/data operations happen within current transaction context. Use begin_transaction() commit_transaction() ensure proper versioning. use replace_table(): Adding new columns - DuckLake UPDATE add columns; use replace_table() Removing columns - Restructure schema select() Versioning needed - Creates snapshots via DROP + CREATE time travel Complex transformations - Apply full dplyr pipelines naturally use update_table() instead: Modifying existing column values (schema changes) Performance critical versioning needed Making targeted corrections specific rows","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/replace_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replace a table with modified data and create a new snapshot — replace_table","text":"","code":"if (FALSE) { # \\dontrun{ # Add new derived columns with versioning begin_transaction() get_ducklake_table(\"adsl\") |>   mutate(     AGE65FL = if_else(AGE >= 65, \"Y\", \"N\"),     AGECAT = case_when(       AGE < 65 ~ \"<65\",       AGE >= 65 & AGE < 75 ~ \"65-74\",       AGE >= 75 ~ \">=75\"     )   ) |>   replace_table(\"adsl\") commit_transaction()  # Remove columns and create new snapshot begin_transaction() get_ducklake_table(\"adsl\") |>   select(-AGE65FL, -AGECAT) |>   replace_table(\"adsl\") commit_transaction() } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/restore_table_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Restore a table to a previous version — restore_table_version","title":"Restore a table to a previous version — restore_table_version","text":"Restores table specific version timestamp, reverting changes made point.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/restore_table_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restore a table to a previous version — restore_table_version","text":"","code":"restore_table_version(   table_name,   version = NULL,   timestamp = NULL,   conn = NULL )"},{"path":"https://tgerke.github.io/ducklake-r/reference/restore_table_version.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restore a table to a previous version — restore_table_version","text":"table_name name table restore version Optional version number restore timestamp Optional timestamp restore (POSIXct character) conn Optional DuckDB connection object. provided, uses default ducklake connection.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/restore_table_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Restore a table to a previous version — restore_table_version","text":"Invisibly returns TRUE success","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/restore_table_version.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Restore a table to a previous version — restore_table_version","text":"function restores table previous state. must specify either version timestamp, . WARNING: operation modifies table easily undone. Consider using within transaction backing data first.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/restore_table_version.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Restore a table to a previous version — restore_table_version","text":"","code":"if (FALSE) { # \\dontrun{ # Restore to version 5 restore_table_version(\"my_table\", version = 5)  # Restore to a specific timestamp restore_table_version(\"my_table\", timestamp = \"2024-01-15 10:00:00\") } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/rollback_transaction.html","id":null,"dir":"Reference","previous_headings":"","what":"Rollback a transaction — rollback_transaction","title":"Rollback a transaction — rollback_transaction","text":"Rolls back current transaction, discarding changes made since transaction began.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rollback_transaction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rollback a transaction — rollback_transaction","text":"","code":"rollback_transaction(conn = NULL)"},{"path":"https://tgerke.github.io/ducklake-r/reference/rollback_transaction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rollback a transaction — rollback_transaction","text":"conn Optional DuckDB connection object. provided, uses default ducklake connection.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rollback_transaction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rollback a transaction — rollback_transaction","text":"Invisibly returns TRUE success","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rollback_transaction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rollback a transaction — rollback_transaction","text":"function discards changes made since begin_transaction() called, reverting database state transaction began.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rollback_transaction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rollback a transaction — rollback_transaction","text":"","code":"if (FALSE) { # \\dontrun{ begin_transaction() # ... make changes ... # Something went wrong, rollback rollback_transaction() } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_delete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete rows from a DuckLake table — rows_delete","title":"Delete rows from a DuckLake table — rows_delete","text":"wrapper around dplyr::rows_delete() in_place = TRUE default, since DuckLake designed -place modifications.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_delete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete rows from a DuckLake table — rows_delete","text":"","code":"rows_delete(   x,   y,   by = NULL,   copy = TRUE,   in_place = TRUE,   unmatched = \"error\",   ... )"},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_delete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete rows from a DuckLake table — rows_delete","text":"x Target table (get_ducklake_table()) y Data frame rows delete (matched '' columns) Column(s) match copy Whether copy y source x (default TRUE) in_place Whether modify table place (default TRUE DuckLake) unmatched handle unmatched rows (default \"error\") ... Additional arguments passed dplyr::rows_delete()","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_delete.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delete rows from a DuckLake table — rows_delete","text":"updated table","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_delete.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delete rows from a DuckLake table — rows_delete","text":"","code":"if (FALSE) { # \\dontrun{ rows_delete(   get_ducklake_table(\"my_table\"),   data.frame(id = c(1, 2, 3)),   by = \"id\" ) } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_insert.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert rows into a DuckLake table — rows_insert","title":"Insert rows into a DuckLake table — rows_insert","text":"wrapper around dplyr::rows_insert() in_place = TRUE default, since DuckLake designed -place modifications.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_insert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert rows into a DuckLake table — rows_insert","text":"","code":"rows_insert(   x,   y,   by = NULL,   copy = TRUE,   in_place = TRUE,   conflict = \"error\",   ... )"},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_insert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert rows into a DuckLake table — rows_insert","text":"x Target table (get_ducklake_table()) y Data frame new rows Column(s) match (conflict detection) copy Whether copy y source x (default TRUE) in_place Whether modify table place (default TRUE DuckLake) conflict handle conflicts (default \"error\") ... Additional arguments passed dplyr::rows_insert()","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_insert.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Insert rows into a DuckLake table — rows_insert","text":"updated table","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_insert.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Insert rows into a DuckLake table — rows_insert","text":"","code":"if (FALSE) { # \\dontrun{ rows_insert(   get_ducklake_table(\"my_table\"),   data.frame(id = 99, value = \"new row\"),   by = \"id\" ) } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_patch.html","id":null,"dir":"Reference","previous_headings":"","what":"Patch rows in a DuckLake table — rows_patch","title":"Patch rows in a DuckLake table — rows_patch","text":"wrapper around dplyr::rows_patch() in_place = TRUE default, since DuckLake designed -place modifications.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_patch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Patch rows in a DuckLake table — rows_patch","text":"","code":"rows_patch(   x,   y,   by = NULL,   copy = TRUE,   in_place = TRUE,   unmatched = \"error\",   ... )"},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_patch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Patch rows in a DuckLake table — rows_patch","text":"x Target table (get_ducklake_table()) y Data frame patches (updates non-NA values) Column(s) match copy Whether copy y source x (default TRUE) in_place Whether modify table place (default TRUE DuckLake) unmatched handle unmatched rows (default \"error\") ... Additional arguments passed dplyr::rows_patch()","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_patch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Patch rows in a DuckLake table — rows_patch","text":"updated table","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_patch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Patch rows in a DuckLake table — rows_patch","text":"","code":"if (FALSE) { # \\dontrun{ # Patch (only update non-NA columns) rows_patch(   get_ducklake_table(\"my_table\"),   data.frame(id = 1, col1 = \"update\", col2 = NA),   by = \"id\" ) } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Update rows in a DuckLake table — rows_update","title":"Update rows in a DuckLake table — rows_update","text":"wrapper around dplyr::rows_update() in_place = TRUE default, since DuckLake designed -place modifications.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update rows in a DuckLake table — rows_update","text":"","code":"rows_update(   x,   y,   by = NULL,   copy = TRUE,   in_place = TRUE,   unmatched = \"error\",   ... )"},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update rows in a DuckLake table — rows_update","text":"x Target table (get_ducklake_table()) y Data frame updates Column(s) match copy Whether copy y source x (default TRUE) in_place Whether modify table place (default TRUE DuckLake) unmatched handle unmatched rows (default \"error\") ... Additional arguments passed dplyr::rows_update()","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_update.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update rows in a DuckLake table — rows_update","text":"updated table","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_update.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update rows in a DuckLake table — rows_update","text":"","code":"if (FALSE) { # \\dontrun{ # Update rows - in_place = TRUE by default rows_update(   get_ducklake_table(\"my_table\"),   data.frame(id = 1, value = \"new\"),   by = \"id\" ) } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_upsert.html","id":null,"dir":"Reference","previous_headings":"","what":"Upsert rows in a DuckLake table — rows_upsert","title":"Upsert rows in a DuckLake table — rows_upsert","text":"wrapper around dplyr::rows_upsert() in_place = TRUE default, since DuckLake designed -place modifications. Optionally adds snapshot metadata operation completes.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_upsert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upsert rows in a DuckLake table — rows_upsert","text":"","code":"rows_upsert(   x,   y,   by = NULL,   copy = TRUE,   in_place = TRUE,   author = NULL,   commit_message = NULL,   commit_extra_info = NULL,   ... )"},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_upsert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upsert rows in a DuckLake table — rows_upsert","text":"x Target table (get_ducklake_table()) y Data frame rows upsert (update existing, insert new) Column(s) match copy Whether copy y source x (default TRUE) in_place Whether modify table place (default TRUE DuckLake) author Optional author name associate snapshot commit_message Optional commit message describing changes commit_extra_info Optional extra information commit ... Additional arguments passed dplyr::rows_upsert()","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_upsert.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upsert rows in a DuckLake table — rows_upsert","text":"updated table","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_upsert.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Upsert rows in a DuckLake table — rows_upsert","text":"function performs upsert operation: updates existing rows inserts new ones. Rows matched using columns specified . author, commit_message, commit_extra_info provided, added snapshot metadata upsert completes.","code":""},{"path":[]},{"path":"https://tgerke.github.io/ducklake-r/reference/rows_upsert.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upsert rows in a DuckLake table — rows_upsert","text":"","code":"if (FALSE) { # \\dontrun{ # Basic upsert rows_upsert(   get_ducklake_table(\"my_table\"),   data.frame(id = c(1, 99), value = c(\"updated\", \"new\")),   by = \"id\" )  # Upsert with metadata rows_upsert(   get_ducklake_table(\"my_table\"),   data.frame(id = c(1, 99), value = c(\"updated\", \"new\")),   by = \"id\",   author = \"Data Team\",   commit_message = \"Update and add records\" ) } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/set_ducklake_connection.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the DuckLake connection — set_ducklake_connection","title":"Set the DuckLake connection — set_ducklake_connection","text":"Set DuckLake connection","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/set_ducklake_connection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the DuckLake connection — set_ducklake_connection","text":"","code":"set_ducklake_connection(conn)"},{"path":"https://tgerke.github.io/ducklake-r/reference/set_ducklake_connection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the DuckLake connection — set_ducklake_connection","text":"conn DuckDB connection object","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/set_snapshot_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Set metadata for the most recent snapshot — set_snapshot_metadata","title":"Set metadata for the most recent snapshot — set_snapshot_metadata","text":"Updates author, commit message, /extra info recent snapshot DuckLake catalog.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/set_snapshot_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set metadata for the most recent snapshot — set_snapshot_metadata","text":"","code":"set_snapshot_metadata(   ducklake_name,   author = NULL,   commit_message = NULL,   commit_extra_info = NULL,   conn = NULL )"},{"path":"https://tgerke.github.io/ducklake-r/reference/set_snapshot_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set metadata for the most recent snapshot — set_snapshot_metadata","text":"ducklake_name name DuckLake catalog author Optional author name associate snapshot commit_message Optional commit message describing changes commit_extra_info Optional extra information commit conn Optional DuckDB connection object. provided, uses default ducklake connection.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/set_snapshot_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set metadata for the most recent snapshot — set_snapshot_metadata","text":"Invisibly returns TRUE success","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/set_snapshot_metadata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set metadata for the most recent snapshot — set_snapshot_metadata","text":"function updates metadata columns ducklake_snapshot_changes table recent snapshot. Call commit_transaction() add audit information commits.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/set_snapshot_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set metadata for the most recent snapshot — set_snapshot_metadata","text":"","code":"if (FALSE) { # \\dontrun{ begin_transaction() # ... make changes ... commit_transaction()  # Add metadata to the snapshot set_snapshot_metadata(   ducklake_name = \"my_ducklake\",   author = \"Data Team\",   commit_message = \"Updated station names for clarity\" ) } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/show_ducklake_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Show the SQL that would be executed by ducklake operations — show_ducklake_query","title":"Show the SQL that would be executed by ducklake operations — show_ducklake_query","text":"function shows SQL generated executed ducklake. useful debugging understanding SQL sent DuckDB.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/show_ducklake_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show the SQL that would be executed by ducklake operations — show_ducklake_query","text":"","code":"show_ducklake_query(.data, table_name = NULL)"},{"path":"https://tgerke.github.io/ducklake-r/reference/show_ducklake_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show the SQL that would be executed by ducklake operations — show_ducklake_query","text":".data dplyr query object (tbl_lazy) table_name target table name operation. provided, extracted table attribute (set get_ducklake_table())","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/show_ducklake_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show the SQL that would be executed by ducklake operations — show_ducklake_query","text":"first argument, invisibly (following show_query convention)","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/show_ducklake_query.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show the SQL that would be executed by ducklake operations — show_ducklake_query","text":"","code":"if (FALSE) { # \\dontrun{ # Show SQL for an update operation (table name inferred) get_ducklake_table(\"my_table\") |>   mutate(status = \"updated\") |>   show_ducklake_query() } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/update_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Update existing column values in a table (in-place, no versioning) — update_table","title":"Update existing column values in a table (in-place, no versioning) — update_table","text":"Update existing column values table (-place, versioning)","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/update_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update existing column values in a table (in-place, no versioning) — update_table","text":"","code":"update_table(.data, table_name, .quiet = FALSE)"},{"path":"https://tgerke.github.io/ducklake-r/reference/update_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update existing column values in a table (in-place, no versioning) — update_table","text":".data dplyr query object (tbl_lazy) mutate() operations table_name Table name update .quiet Logical, whether suppress debug output (default FALSE backward compatibility)","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/update_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update existing column values in a table (in-place, no versioning) — update_table","text":"Invisibly returns SQL statement string executing ","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/update_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update existing column values in a table (in-place, no versioning) — update_table","text":"function performs -place UPDATE operations existing columns. Important limitations: add remove columns - modifies values existing columns create snapshots - UPDATE operations modify -place without creating snapshots, even wrapped transactions. CREATE operations trigger snapshots. columns must exist - column referenced mutate() must already exist table Use replace_table() need : Add new derived columns Remove columns Create new versioned snapshot Use update_table() : Making targeted value corrections existing columns Performance critical versioning needed Updating specific rows filter()","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/update_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update existing column values in a table (in-place, no versioning) — update_table","text":"","code":"if (FALSE) n#' # Correct a specific value (no versioning needed) get_ducklake_table(\"adsl\") |>   mutate(SAFFL = if_else(USUBJID == \"01-701-1015\", \"N\", SAFFL)) |>   update_table(\"adsl\") #> === DEBUG: update_table called === #> Error in mutate(get_ducklake_table(\"adsl\"), SAFFL = if_else(USUBJID ==     \"01-701-1015\", \"N\", SAFFL)): could not find function \"mutate\"  # Update multiple columns get_ducklake_table(\"adae\") |>   mutate(     AESEV = if_else(AESEV == \"MILD\", \"MODERATE\", AESEV),     AESER = if_else(AESEV == \"SEVERE\", \"Y\", AESER)   ) |>   update_table(\"adae\") #> === DEBUG: update_table called === #> Error in mutate(get_ducklake_table(\"adae\"), AESEV = if_else(AESEV == \"MILD\",     \"MODERATE\", AESEV), AESER = if_else(AESEV == \"SEVERE\", \"Y\",     AESER)): could not find function \"mutate\"  # \\dontrun{}"},{"path":"https://tgerke.github.io/ducklake-r/reference/upsert_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Upsert data from a dplyr query into a DuckLake table — upsert_table","title":"Upsert data from a dplyr query into a DuckLake table — upsert_table","text":"Performs MERGE operation: updates existing rows inserts new ones based matching keys. pipeline-based version rows_upsert() use dplyr queries.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/upsert_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upsert data from a dplyr query into a DuckLake table — upsert_table","text":"","code":"upsert_table(.data, table_name = NULL, by, .quiet = TRUE)"},{"path":"https://tgerke.github.io/ducklake-r/reference/upsert_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upsert data from a dplyr query into a DuckLake table — upsert_table","text":".data dplyr query object (tbl_lazy) source data table_name target table name. provided, extracted table attribute (set get_ducklake_table()) Character vector column names match (merge keys) .quiet Logical, whether suppress debug output (default TRUE)","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/upsert_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upsert data from a dplyr query into a DuckLake table — upsert_table","text":"result executing MERGE statement","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/upsert_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Upsert data from a dplyr query into a DuckLake table — upsert_table","text":"pipeline-based approach upserts, ideal transforming data dplyr verbs. upserting data.frames directly, see rows_upsert(). function generates DuckDB INSERT ... CONFLICT statement (provides MERGE/UPSERT functionality). Rows matched based columns specified . match found, row updated; , new row inserted. Note: function requires table PRIMARY KEY UNIQUE constraint columns specified . table constraints, use rows_upsert() instead.","code":""},{"path":[]},{"path":"https://tgerke.github.io/ducklake-r/reference/upsert_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upsert data from a dplyr query into a DuckLake table — upsert_table","text":"","code":"if (FALSE) { # \\dontrun{ # Upsert data from a computed query get_ducklake_table(\"staging_table\") |>   mutate(processed = TRUE) |>   upsert_table(\"target_table\", by = \"id\")  # Upsert with table name inferred get_ducklake_table(\"my_table\") |>   filter(status == \"active\") |>   mutate(last_updated = Sys.time()) |>   upsert_table(by = c(\"id\", \"version\")) } # }"},{"path":"https://tgerke.github.io/ducklake-r/reference/with_transaction.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute code within a transaction — with_transaction","title":"Execute code within a transaction — with_transaction","text":"Wraps code execution transaction, automatically committing success rolling back error. provides R-idiomatic safer way handle transactions compared manually calling begin_transaction() commit_transaction().","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/with_transaction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute code within a transaction — with_transaction","text":"","code":"with_transaction(   expr,   author = NULL,   commit_message = NULL,   commit_extra_info = NULL,   conn = NULL )"},{"path":"https://tgerke.github.io/ducklake-r/reference/with_transaction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute code within a transaction — with_transaction","text":"expr R expression code block execute within transaction. Can single statement {...} block containing multiple statements. author Optional author name associate snapshot commit_message Optional commit message describing changes commit_extra_info Optional extra information commit conn Optional DuckDB connection object. provided, uses default ducklake connection.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/with_transaction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Execute code within a transaction — with_transaction","text":"Invisibly returns result expression","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/with_transaction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Execute code within a transaction — with_transaction","text":"function provides automatic error handling cleanup transactions: Begins transaction executing code Executes provided expression success: commits transaction adds metadata (provided) error: automatically rolls back transaction re-throws error pattern similar withr::with_*() functions provides better safety guarantees manually managing transactions.","code":""},{"path":"https://tgerke.github.io/ducklake-r/reference/with_transaction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Execute code within a transaction — with_transaction","text":"","code":"if (FALSE) { # \\dontrun{ # Single operation with_transaction(   create_table(mtcars, \"cars\"),   author = \"Data Team\",   commit_message = \"Add cars dataset\" )  # Multiple operations in a block with_transaction({   create_table(mtcars, \"cars\")   create_table(iris, \"flowers\") }, author = \"Data Team\", commit_message = \"Add datasets\")  # With dplyr pipeline with_transaction(   get_ducklake_table(\"cars\") |>     mutate(kpl = mpg * 0.425144) |>     replace_table(\"cars\"),   author = \"Data Team\",   commit_message = \"Add km/L column\" )  # Automatic rollback on error tryCatch(   with_transaction({     create_table(mtcars, \"cars\")     stop(\"Simulated error\")  # Transaction will be rolled back   }),   error = function(e) message(\"Transaction was rolled back: \", e$message) ) } # }"}]
